{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca02abad-79b5-4af4-8615-bfd2eaec3a7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "519a6d07-0dbf-41b4-841f-cc9fae972b66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json \n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "897f52ae-101d-492c-ad5b-bf3018452e04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1da1d11b-a112-45cf-9d75-59c1f7af74ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prompts\n",
    "\n",
    "system_prompt = \"You are a tutor and helps with the user questions in detail with markdown respond with key point \\\n",
    "considering the recent development around the world, keep the response in most appropriate tone \\n\"\n",
    "\n",
    "system_prompt += \"Some of Examples are\"\n",
    "system_prompt += \"\"\"\n",
    "{\"question\": \"1+1?\", \"response\": \"2\"},\n",
    "{\"question\": \"why we shouls learn LLM Models?\", \"response\": \" Learning about Large Language Models (LLMs) is important because they are a rapidly evolving technology with the potential to significantly impact various industries, offering advanced capabilities in text generation, translation, information retrieval, and more, which can be valuable for professionals across diverse fields, allowing them to enhance their work and gain a competitive edge by understanding and utilizing these powerful language processing tools.\\ \n",
    "Key reasons to learn about LLMs:\\\n",
    "Career advancement:\\\n",
    "Familiarity with LLMs can open up new career opportunities in fields like AI development, natural language processing (NLP), content creation, research, and customer service, where LLM applications are increasingly being implemented. \\\n",
    "Increased productivity:\\\n",
    "LLMs can automate repetitive tasks like writing emails, summarizing documents, generating reports, and translating text, freeing up time for more strategic work. \\\n",
    "Enhanced decision-making:\\\n",
    "By providing insights from large datasets, LLMs can assist in informed decision-making across various industries, including business, healthcare, and finance. \\\n",
    "Creative potential:\\\n",
    "LLMs can be used to generate creative content like poems, stories, scripts, and marketing copy, fostering innovation and new ideas. \\\n",
    "Understanding the technology landscape:\\\n",
    "As LLMs become increasingly prevalent, understanding their capabilities and limitations is crucial for navigating the evolving technological landscape. \\\n",
    "What is a large language model (LLM)? - Cloudflare\\\n",
    "A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other t...\\\n",
    " \"},\n",
    "{\"question\": \"what is the future of AI?\", \"response\": \"AI is predicted to grow increasingly pervasive as technology develops, revolutionising sectors including healthcare, banking, and transportation\"},\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "585931eb-92cc-42ee-ac71-6c8adc5a9b29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "745b9733-12b1-42a8-bba6-35822097608f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "user_question = \"\"\"\n",
    "How important it is for a Data Engineers to learn LLM, Considering the evolution of AI now a days?.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9688a464-e485-401b-b2ae-5124892d31ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def ask_tutor(question):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": question},\n",
    "            {\"role\": \"user\", \"content\": system_prompt}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "\n",
    "# call the gpt-4o-mini to answer with streaming\n",
    "ask_tutor(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63193502-9a87-454d-b3f2-ef97b9e069ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": user_question}\n",
    "]\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "        \"model\": MODEL_LLAMA,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "reply = response['message']['content']\n",
    "display(Markdown(reply))\n",
    "\n",
    "# # Process the response stream\n",
    "# for line in response.iter_lines():\n",
    "#     if line:  # Skip empty lines\n",
    "#         try:\n",
    "#             # Decode the JSON object from each line\n",
    "#             response_data = json.loads(line)\n",
    "#             if \"message\" in response_data and \"content\" in response_data[\"message\"]:\n",
    "#                 print(response_data[\"message\"][\"content\"])\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             print(f\"Failed to decode JSON: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "week1 EXERCISE",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
