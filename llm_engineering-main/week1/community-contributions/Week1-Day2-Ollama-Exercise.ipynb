{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57b39e75-1a8c-4dc7-b7fa-f2f110160248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# First Project\n",
    "Ollama -> Summary\n",
    "huggingface_hub -> \"facebook/m2m100_418M\" for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7dcc26b-aa55-466b-a905-4d2b4d5d3442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42f3f473-81e0-4f32-b004-8d90e4e8aa3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "949eaecd-cb5f-4fda-be6d-bf6766bb2ecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "huggingface_url = \"https://huggingface.co/learn/ml-for-3d-course\"\n",
    "huggingface_website = Website(huggingface_url)\n",
    "\n",
    "huggingface_data = {\n",
    "    \"title\": huggingface_website.title,\n",
    "    \"text\": huggingface_website.text\n",
    "}\n",
    "print(huggingface_data)\n",
    "\n",
    "with open('ml_for_3d_course_data.json', 'w') as f:\n",
    "    json.dump(huggingface_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f7ac183-7cdb-4fe3-9353-b8d26640cb40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# huggingface_data 'text' value\n",
    "huggingface_text = huggingface_data['text']\n",
    "\n",
    "# Summary\n",
    "response_summary = ollama.chat(model=\"llama3.2:latest\", messages=[{\"role\": \"user\", \"content\": f\"Summarize the following text: {huggingface_text}\"}])\n",
    "print(response_summary)\n",
    "\n",
    "# print summary\n",
    "summary_huggingface_text = response_summary.message['content']\n",
    "print(\"Summary Text:\", summary_huggingface_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b72ecb4c-cc1c-4ad3-a3cb-0f8103419e01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# HuggingFace Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c7b0cb8-0b92-4555-b9a6-e205e0541a6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "url = \"https://huggingface.co/learn/ml-for-3d-course\"\n",
    "website = Website(url)\n",
    "print(website.title)  \n",
    "print(website.text[:1000])\n",
    "\n",
    "data = {\n",
    "    \"title\": website.title,\n",
    "    \"text\": website.text\n",
    "}\n",
    "\n",
    "with open('ml_for_3d_course_data.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f8cf2c1-63e8-4ce6-aee2-a2354f1b1eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bed7e980-ddf8-46cc-ba09-52c7b235b2d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6adfffe0-7f37-4096-86cc-3be5fd8c2d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "# Load the M2M100 model and tokenizer\n",
    "model_name = \"facebook/m2m100_418M\"\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the saved JSON file\n",
    "with open('ml_for_3d_course_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract text from the loaded data\n",
    "text = data[\"text\"]\n",
    "\n",
    "# Set the source language to English and target language to Korean\n",
    "source_lang = \"en\"\n",
    "target_lang = \"ko\"\n",
    "\n",
    "# Set the language for tokenizer (important for M2M100)\n",
    "tokenizer.src_lang = source_lang\n",
    "tokenizer.tgt_lang = target_lang\n",
    "\n",
    "# Split text into smaller chunks if it's too large\n",
    "# This step ensures we don't exceed the model's maximum length (512 tokens)\n",
    "max_input_length = 512\n",
    "chunks = [text[i:i+max_input_length] for i in range(0, len(text), max_input_length)]\n",
    "\n",
    "print(chunks)\n",
    "# Initialize a list to hold the translated text\n",
    "translated_chunks = []\n",
    "\n",
    "# Iterate through each chunk and translate it\n",
    "for chunk in chunks:\n",
    "    # Tokenize the chunk\n",
    "    encoded = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Generate translation from the model, forcing the output to be in Korean\n",
    "    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(target_lang), max_length=512)\n",
    "\n",
    "    # Decode the translated tokens to text\n",
    "    translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    translated_chunks.append(translated_text)\n",
    "\n",
    "# Combine all translated chunks back together\n",
    "final_translated_text = ' '.join(translated_chunks)\n",
    "print(\"Translated Text:\", final_translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bc429b2-ce52-44b3-8f82-41d5aacbe900",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Ollama API URL 설정\n",
    "ollama_url = \"http://localhost:11411/v1/models/facebook/m2m100_418M/generate\"\n",
    "\n",
    "# 저장된 JSON 파일 로드\n",
    "with open('ml_for_3d_course_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 텍스트 추출\n",
    "course_text = data[\"text\"]\n",
    "\n",
    "# 번역할 소스 언어 및 타겟 언어 설정\n",
    "source_language = \"en\"\n",
    "target_language = \"ko\"\n",
    "\n",
    "# 데이터 준비\n",
    "payload = {\n",
    "    \"input_text\": course_text,\n",
    "    \"src_lang\": source_language,\n",
    "    \"tgt_lang\": target_language\n",
    "}\n",
    "\n",
    "# API 호출\n",
    "response = requests.post(ollama_url, json=payload)\n",
    "\n",
    "# 응답 확인\n",
    "if response.status_code == 200:\n",
    "    translated_course_text = response.json().get(\"translated_text\", \"Translation failed\")\n",
    "    print(\"Translated Course Text:\", translated_course_text)\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Week1-Day2-Ollama-Exercise",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
