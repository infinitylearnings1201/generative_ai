{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d82979c6-1be6-4cac-8173-c4dcd39d7b26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "GHsssBgWM_l0"
   },
   "source": [
    "# üîç Predicting Item Prices from Descriptions (Part 7)\n",
    "---\n",
    "- Data Curation & Preprocessing\n",
    "- Model Benchmarking ‚Äì Traditional ML vs LLMs\n",
    "- E5 Embeddings & RAG\n",
    "- Fine-Tuning GPT-4o Mini\n",
    "- Evaluating LLaMA 3.1 8B Quantized\n",
    "- Fine-Tuning LLaMA 3.1 with QLoRA\n",
    "- ‚û°Ô∏è Evaluating Fine-Tuned LLaMA\n",
    "- Summary & Leaderboard\n",
    "\n",
    "---\n",
    "\n",
    "# üß™ Part 7: Evaluating the Fine-Tuned LLaMA 3.1 8B (Quantized)\n",
    "\n",
    "- üßë‚Äçüíª Skill Level: Advanced\n",
    "- ‚öôÔ∏è Hardware: ‚ö†Ô∏è GPU required - use Google Colab\n",
    "- üõ†Ô∏è Requirements: üîë HF Token\n",
    "- Tasks:\n",
    "    - Load the tokenizer and fine-tuned base model\n",
    "    - Load the PEFT adapter for the fine-tuned weights\n",
    "    - Run evaluation ‚Äî the moment of truth!\n",
    "\n",
    "üîî **Reminder:**  \n",
    "As mentioned in Part 6, I fine-tuned the model on only 20K samples.  \n",
    "In this notebook, we‚Äôll evaluate both this model and the full 400K-sample version fine-tuned by our instructor.\n",
    "\n",
    "---\n",
    "üì¢ Find more LLM notebooks on my [GitHub repository](https://github.com/lisekarimi/lexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a1e6020-ad7a-43d7-94d5-3d924d9eec10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MDyR63OTNUJ6"
   },
   "outputs": [],
   "source": [
    "# Install required packages in Google Colab\n",
    "%pip install -q datasets transformers torch peft bitsandbytes matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c71c0705-537b-409a-92cc-218c062c7d50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-yikV8pRBer9"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, set_seed\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1aac70f5-ba7a-4e50-9422-8d90bbde9c1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WyFPZeMcM88v"
   },
   "outputs": [],
   "source": [
    "# Google Colab User Data\n",
    "# Ensure you have set the following in your Google Colab environment:\n",
    "hf_token = userdata.get('HF_TOKEN')\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "084f4c64-2ac3-4074-b357-a8b42a1b23fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "30lzJXBH7BcK"
   },
   "outputs": [],
   "source": [
    "# Helper class for evaluating model predictions\n",
    "\n",
    "GREEN = \"\\033[92m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "RED = \"\\033[91m\"\n",
    "RESET = \"\\033[0m\"\n",
    "COLOR_MAP = {\"red\":RED, \"orange\": YELLOW, \"green\": GREEN}\n",
    "\n",
    "class Tester:\n",
    "\n",
    "    def __init__(self, predictor, data, title=None, size=250):\n",
    "        self.predictor = predictor\n",
    "        self.data = data\n",
    "        self.title = title or predictor.__name__.replace(\"_\", \" \").title()\n",
    "        self.size = size\n",
    "        self.guesses = []\n",
    "        self.truths = []\n",
    "        self.errors = []\n",
    "        self.sles = []\n",
    "        self.colors = []\n",
    "\n",
    "    def color_for(self, error, truth):\n",
    "        if error<40 or error/truth < 0.2:\n",
    "            return \"green\"\n",
    "        elif error<80 or error/truth < 0.4:\n",
    "            return \"orange\"\n",
    "        else:\n",
    "            return \"red\"\n",
    "\n",
    "    def run_datapoint(self, i):\n",
    "        datapoint = self.data[i]\n",
    "        guess = self.predictor(datapoint[\"text\"])\n",
    "        truth = datapoint[\"price\"]\n",
    "        error = abs(guess - truth)\n",
    "        log_error = math.log(truth+1) - math.log(guess+1)\n",
    "        sle = log_error ** 2\n",
    "        color = self.color_for(error, truth)\n",
    "        # title = datapoint[\"text\"].split(\"\\n\\n\")[1][:20] + \"...\"\n",
    "        self.guesses.append(guess)\n",
    "        self.truths.append(truth)\n",
    "        self.errors.append(error)\n",
    "        self.sles.append(sle)\n",
    "        self.colors.append(color)\n",
    "        # print(f\"{COLOR_MAP[color]}{i+1}: Guess: ${guess:,.2f} Truth: ${truth:,.2f} Error: ${error:,.2f} SLE: {sle:,.2f} Item: {title}{RESET}\")\n",
    "\n",
    "    def chart(self, title):\n",
    "        # max_error = max(self.errors)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        max_val = max(max(self.truths), max(self.guesses))\n",
    "        plt.plot([0, max_val], [0, max_val], color='deepskyblue', lw=2, alpha=0.6)\n",
    "        plt.scatter(self.truths, self.guesses, s=3, c=self.colors)\n",
    "        plt.xlabel('Ground Truth')\n",
    "        plt.ylabel('Model Estimate')\n",
    "        plt.xlim(0, max_val)\n",
    "        plt.ylim(0, max_val)\n",
    "        plt.title(title)\n",
    "\n",
    "        # Add color legend\n",
    "        from matplotlib.lines import Line2D\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='w', label='Accurate (green)', markerfacecolor='green', markersize=8),\n",
    "            Line2D([0], [0], marker='o', color='w', label='Medium error (orange)', markerfacecolor='orange', markersize=8),\n",
    "            Line2D([0], [0], marker='o', color='w', label='High error (red)', markerfacecolor='red', markersize=8)\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def report(self):\n",
    "        average_error = sum(self.errors) / self.size\n",
    "        rmsle = math.sqrt(sum(self.sles) / self.size)\n",
    "        hits = sum(1 for color in self.colors if color==\"green\")\n",
    "        title = f\"{self.title} Error=${average_error:,.2f} RMSLE={rmsle:,.2f} Hits={hits/self.size*100:.1f}%\"\n",
    "        self.chart(title)\n",
    "\n",
    "    def run(self):\n",
    "        self.error = 0\n",
    "        for i in range(self.size):\n",
    "            self.run_datapoint(i)\n",
    "        self.report()\n",
    "\n",
    "    @classmethod\n",
    "    def test(cls, function, data):\n",
    "        cls(function, data).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6a4616f-1d1e-4336-9a15-5eecf4b2739a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üì• Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e49e5b41-854f-416c-989c-00529bef418e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #If you face NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported run:\n",
    "# %pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77943d3d-6878-41ea-b4d8-930892d916b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "61f42f612e98467684716cc7421c7554",
      "a7e864c2ae21482e8bcdbc42a5a65309",
      "63405c5e47da4652b052ee6099ead31e",
      "0864a38b1c494308a07defced89f4fe3",
      "8f089946a97d4becb3ff06b7a65595a2",
      "42b865ac9e4f4ecaa475c4d69929e401",
      "3478290afe1d48268c7c07206c212eda",
      "f21c0db9205f4c40a2f9ea1ddd66b59e",
      "4604f38122454bc1b1826311a326eb12",
      "6e2b95e33cab4fe9b9f555195b634fac",
      "b8f0f357a61c4502962f385291c3bac8",
      "fa49b7e56b054faca67334e08bbf622c",
      "243d84401ba24360a42c2636d7984772",
      "bbcf01edcbcd425b9ca1e61e80f6df4f",
      "17b41698c33044c7942e66e63c5c2d2d",
      "14dfccde2f6a47679cea42ce965b6ef2",
      "6a1570c8980b4d5ebac78348f79c4f1b",
      "44f1922676f3417fb7baccd92bf53cea",
      "176b023546bc4053a4d484205d7ab200",
      "b02018254c4b4fb680e382974380c331",
      "766aba35ebf54996990e075e4f692f96",
      "24ceffd3b8c64e5f983e52d743ebef8d",
      "5b9076b6c05a4454a7233302114b9d8c",
      "4bfbd393271844de825a53c7d639fa60",
      "3313091548bf414fabf84f5aa2c85d14",
      "f98c7fe4ad6d4649a7a104f973992be0",
      "fd1eb06d0aa64ba59ae9bb214f2c94ed",
      "24237203b2c44709b20ca84b95387849",
      "7910e6a4881a43638c4e91dd0f024092",
      "f22dad57ee324ca8b927f9a3b8cc6edc",
      "20a702b1ccbe499eabf70af974561417",
      "48f72254ce6f408c94bf56a3919c032e",
      "6bf00cd26256489fb209b8b51ca9fb0e",
      "da3c453facaf41b6bc89d311d9f1ce74",
      "78487c1a13e84e7bb35a72a07ad9b681",
      "3866fe39fcc34120a0b4c4b36c8eaa6c",
      "54de8e445909429f9d7ca9ad02e8f190",
      "eeda8994cb8d46cc9d5c2212907ab869",
      "b670675ee9bc4689a34f997d0da13b82",
      "56727a21bb4648fe8ae46d3a61b39f4a",
      "da89c856fbf746b496d37cbef92305b9",
      "2f4ba348ef7246af8b1cd04352bcbd1d",
      "0d86b4a93411494eb8e725440e393cff",
      "203c4888674c46bba1033639ad4286a2",
      "005dac04aacb4955ae079d36bfc4cd19",
      "68ff796bdee44aa380324374ae38fd25",
      "411691dce3f1457cb3ee9e8ad652d61d",
      "f0fc209cb9e74d0ca3c0c9b14b1450e0",
      "6e2155c3ad3243508dff34919eecd0a2",
      "68891d88fe7e417abbd508d2089e7960",
      "8e1ab77817bc4ec2835b195a0beb1096",
      "c638e3a09f6b4caaa078e242b010744e",
      "ee9abd78adb54984868ebee19f638e25",
      "8280e432938b4e9794c95e47bb9c02fa",
      "abdd2ff8028b432091434805f81c455c"
     ]
    },
    "id": "cvXVoJH8LS6u",
    "outputId": "6308b124-a922-4e82-fb6a-5933d3c324e0"
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = \"lisekarimi/pricer-data\"\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "train = dataset['train']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b269156-db0f-4de5-a4cf-7e47099d1a75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xb86e__Wc7j_",
    "outputId": "8b699099-7414-4663-fab1-d069d3ec3d35"
   },
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be8fd58f-e2dd-4284-a0af-2c3c3b8c4fe8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qJWQ0a3wZ0Bw"
   },
   "source": [
    "## üì• Load Tokenizer and Model\n",
    "The fine-tuned model (PeftModel) only holds the LoRA adapters, so it requires the base model to apply them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da84d037-bbe1-4760-9ed3-49ff1547205b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "aee2cb6b13d64f1dab9f8190a274bbc0",
      "547a2807263e4295af11da5a43ccf5b7",
      "00b57ab6c0c44e39ad6fa27b7e5a085b",
      "d51c826dc6d749b38ce7e5fdfc730086",
      "f276602665c148999240ef916aa8a9c8",
      "9d83d7056aed43a59d82955bdb8f272d",
      "7a71aedc0f49430ba7c71040c5fa2529",
      "108880a9a7bb4a73837889ad2a25fd77",
      "0163275024a041e2bc9fba947c371269",
      "555a494cbcda41e79ee4584a8122774b",
      "5dfbe2af8afc43c691c34c52a47c9790",
      "25edb5ab02c3402998b75cffc13d0a55",
      "9a4f0361323540aa8428054a0d98ecb3",
      "cf149d1eceae43a9808e142fbfe5d4ff",
      "de86c9338690424fa0052e5b055cea88",
      "2acb3368945a48aeaf9fbc6d22e9238d",
      "4c4c4b1507814037bcea0519ec43ba26",
      "6d37385e79904b7ca267ad165774f962",
      "b14a5f0f71094aa98403edd429cb882e",
      "31b28b6183c644f9b5601208a1f72499",
      "d3cddc62e0fb4256bf4c74f6a59e686b",
      "82cb2192839e451292b27a186daaa7c1",
      "2e038c429eed4abdae8d27a7226d7298",
      "364c4658aba64512a1f50cdad9cc12f8",
      "fde7b1ab1e224fec8e9b761e703b53dd",
      "ad5db9c88ce64f73992d2e274ca1206a",
      "0e7ada829b22485ca7a628d2c464f3f1",
      "ec4f7d2076db4f6a856ab0d5e8edffbd",
      "3f00114026a4417db1b142e5bcb7a695",
      "e4e9cf32b99848baa6a587fb235ce6b5",
      "a109b5ee80574e40a14fa1e186f4f9f4",
      "af569da703694c27aa9ca2ddce6c4923",
      "886bb94abf2c437eb8505222c4336e85",
      "f668156d681e47f39e553f127a44261d",
      "9bb3d0deaac6439e9ad67c2bc0565ff4",
      "762b36fde5ac4a2982152f3babfa3ed9",
      "141911ee360d42ab8dd3b7fa3563bbf0",
      "340eae69eeaf4e458e6d8134018f4ad4",
      "3226e3a8c4564f6fbd6ffb3eeb7b45e7",
      "6ed52680f866470da1e8d4a48b6e42fb",
      "6d8a206edb824c5eb06c803e8cab14de",
      "86fd4472a7a84940a54f24104689a74d",
      "916c0e20af5e4b78a5e86532b0c9a3e8",
      "62dd475c101e4859a48ee57a272f71bc",
      "a8b7185a12c94adca0e63563d7df3ce4",
      "47d57186838d466fb91b6666df85d1b4",
      "9d37814d818c466c90892bf1f6e9a190",
      "b5fdba30791649a792d192a131890a4e",
      "789fe6f5489345c6a8b6a889d20e0ca0",
      "5ce12a0983bb49f1a871598a6b9a0a13",
      "d9eb89d218a44f21bb4447040e5c8925",
      "b04aaa7931e74297a55bca3ebf4ded1d",
      "837708f48ded4d78b7ad2e0dc6464e9c",
      "32236e0d0b3e46e4b2c26b7ccb63c89e",
      "499acde0cedf4ea1a90415f98660aaa5",
      "840d3e7824944889ac2091b35f0c17c0",
      "08f2fae4688b45729d8f5bf53837e56d",
      "133bb5607eb0457888b1fe4e8d3fab3e",
      "46bfe5feb9074050b556d804a544140d",
      "4c3b0c2d04d24ec6abe8acbadb420712",
      "eda1fcca6987495b87cf2206f93a0ecb",
      "00b803cf92754db1bbea8ca909e5ccef",
      "17e17b928555462abfbfa4caf7992427",
      "35f90fa89e8842cdaa487b59da45b3e8",
      "2887ef88074c4591b710688fa76329bf",
      "0a0c5f00b3cc477e8b7e06550fc6f1cb",
      "3b079fe81b7b44d796c531bec1754637",
      "e82f8ac6e8eb4ed6a6743e10b8b99904",
      "1f7de1e2970c4c8fbfe1ab400297e1a7",
      "7ea0d8782a1f4cca9a64b95fe47e8a2e",
      "689b49d52b8f4efb94f80d76a0fefab3",
      "2005939305c442f7bed3b83ea16e13b1",
      "1a6f2631e29444818fdbd9a0de265367",
      "6bfc89e091a5448d94d2ea559ce43a21",
      "bfc12d40caf4481280888506dfa01505",
      "a1fb82d5761843a49a0993ff937cb40d",
      "4c9c567918ee478a817b51e2a204d915",
      "305623f276ba45e5a57727d1829158e1",
      "b2722e271f78405b9151804ffc522530",
      "963435e51a7a4ce98510c0372cd05030",
      "d394cfc6af384a39b87c72ac6a3788d9",
      "2c621a7a90ed4bfd8b52cea9c79e11c1",
      "59ac0bb5c046448fbf16a27d2c3205f8",
      "7617f5670879416d9dbc2dabda76ef4d",
      "b32d6d6ff5dd4ac4adfb063205111707",
      "38f3a7159fc34d89bc18e4225473615d",
      "2a2c386e432f429f86c303d71472b480",
      "ece25eb325004ae48ec5ec00055dd845",
      "68e2b37bbd9a44f8a6032526acbf9ea6",
      "3af191957e3f453ba803a1c01d6969ae",
      "29dba394a6664e0f8984bcb966ccf19b",
      "d84373a3f97245ae94bfb666c7e93a17",
      "9f917250ccbf4078a90fda1eec71c6f4",
      "8171dd4382d24f0a83484fbf967fec03",
      "6f97606a500548e980c6481d756c72eb",
      "6d1054047d4645a69c272484fd9e0c04",
      "7fd14d942d2246bf8df28eca28e13fb2",
      "0dabd208524f426bb5c643791e736413",
      "368dea7bbf144cf0a667493cb23bddab",
      "d6b14f8e43754283ad96543c4c1ffee6",
      "f78562ef15524795bb9be326dcaab502",
      "b01c8091b96444f687a49c5c51b5faf7",
      "baab647e635a46ababa58993965a8159",
      "25d9a9b78d554f8fbe92d7e805640c3b",
      "95726f4b9bc34434b9d00fcdfe2ff87e",
      "a7b835a668ef40c986a6fd51e464d1f4",
      "188cac6192fc4b91be3ca5b01bab1d91",
      "3537ef715f3447388625ee606555bb85",
      "322ca0ccce644c48a2a0f4b44a38776d",
      "cc3726d026594cb6ac2d6bafb16562ac",
      "f48cc4a0a5d041cf9391a99353ff46af",
      "05134ca3a9954341951ff958ff30fe0a",
      "3a6aa623f1dd41b8940a41b509fa7500",
      "fd58111bb44347b8bdcb984a0e86f9b7",
      "c16cfb96177640a991c5509e652c85b9",
      "adc0ffacba0846fabd76ed7955397077",
      "e074da8f28d84ec891f22e30b86fb954",
      "0b53df078f4a4a259b677ccccbdf46cd",
      "954d5fa3b18a49589717cfc31fb58779",
      "af0beb46b198458794c85803fe5af47f",
      "c7322d41ae4c4068880521a136e923b4",
      "391d834aa8734d7b9a97c03cab5e1e7d",
      "5d779fc6bb1244449a68cf62dfd15698",
      "197ca7f2357a4a2c89f5f3da3844c606",
      "df4d22e6876b4c0082a7ace3281ff4e5",
      "28d44cfae7de4b62be11020d9015f92c",
      "3e8d7274ee3a4dfbbdd44ea0b2cd61b6",
      "fa768ce193b94a4882a1e796e69cffea",
      "c37a4882e4474f8690c4b479baf2d785",
      "68a033bbcb4d4774bdb115e09d78365b",
      "10b5e7970aa04bd6b3384aa645c48d92",
      "f838b073dd254bb091a7db7175cd2ce8"
     ]
    },
    "id": "lAUAAcEC6ido",
    "outputId": "b2983922-5036-4083-8cba-0cb3f51fbc51"
   },
   "outputs": [],
   "source": [
    "BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Reduce the precision to 4 bits\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load the Tokenizer and the Model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d002ed5-0150-4ae4-84c0-c69980ecdbc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2RJ0G-WRJGMK"
   },
   "source": [
    "## üß™ Load and Evaluate the Fine-Tuned Model with PEFT Adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4868fc1c-b8c5-4529-a2ce-7bd62c3ec9cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 20K Sample Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9042d885-4e3b-4540-b95e-6b62def9a27c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f0c0a20172294f77a0306801f8d76fb7",
      "f68ee0810c2a4ac087ac6ece5279fb09",
      "8aa12b380191454ebf55e8b42d0e0f2b",
      "63f6cfa30a274ee3835671d8e39a85ef",
      "0b980946a50d4248a4c63ef117fc2e8f",
      "18283c6dee9447ddaca34ad267773e48",
      "a7d10d9147df4adebf913e3023c2a3a4",
      "5886ca455d4d4aefa617478f4f69a3ca",
      "8c0e83bce4f74e7ba337fc9af5b977b8",
      "00dbc32bdb0440c0bc3ba2cc6677b04c",
      "243e6d8479ac4958a8d877e28f9b514a",
      "10b7df1ecfab4e5cb146932fc4fb2c17",
      "07c6fd1fe1ac442dbeb7037161841b78",
      "88adf6ab3f3e476fa66ad22e9ff49aa8",
      "fe522e9cee55448a9c13a5daaad5e7e7",
      "4b1b9e5a67e54a3b90f2c113355e735a",
      "5cdbdf93af9344ccabd7c3f236446541",
      "c4af3ca6696d4fcd9b831d825456c7fa",
      "525b1673c902412db32691056d49fd35",
      "42de37b9a74143b4a851a178c484a706",
      "f5f42d9201dc4fbaaa9c684fdb748d4a",
      "10a0e99256a149a0a94ff652a4fd259a"
     ]
    },
    "id": "R_O04fKxMMT-",
    "outputId": "06fc64f8-3407-460b-e093-0293e958915e"
   },
   "outputs": [],
   "source": [
    "# Load lisekarimi model (trained on 20K datapoints)\n",
    "\n",
    "FINETUNED_MODEL = \"lisekarimi/llama3-pricer-2025-04-08_18.44.04-size20000\"\n",
    "fine_tuned_model = PeftModel.from_pretrained(base_model, FINETUNED_MODEL)\n",
    "print(f\"Memory footprint: {fine_tuned_model.get_memory_footprint() / 1e6:.1f} MB\")\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3169fef5-06c4-493d-bba7-0ac3e79e730c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Je5dR8QEAI1d"
   },
   "outputs": [],
   "source": [
    "# Gets top 3 predicted tokens from the model\n",
    "# Filters valid numeric outputs (prices)\n",
    "# Returns a weighted average based on token probabilities\n",
    "\n",
    "# This code would be more complex if we couldn't take advantage of the fact\n",
    "# That Llama generates 1 token for any 3 digit number\n",
    "\n",
    "top_K = 3\n",
    "\n",
    "def improved_model_predict(prompt, device=\"cuda\"):\n",
    "    set_seed(42) # Reproducibility : same prompt = same o/p every time\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = torch.ones(inputs.shape, device=device)\n",
    "\n",
    "    with torch.no_grad(): # Do not track gradients during inference\n",
    "        outputs = fine_tuned_model(inputs, attention_mask=attention_mask)\n",
    "        next_token_logits = outputs.logits[:, -1, :].to('cpu')\n",
    "\n",
    "    next_token_probs = F.softmax(next_token_logits, dim=-1)\n",
    "    top_prob, top_token_id = next_token_probs.topk(top_K)\n",
    "\n",
    "    prices, weights = [], [] # weights = corresponding probabilities\n",
    "\n",
    "    for i in range(top_K):\n",
    "      predicted_token = tokenizer.decode(top_token_id[0][i])\n",
    "      probability = top_prob[0][i]\n",
    "\n",
    "      try:\n",
    "        result = float(predicted_token)\n",
    "      except ValueError as e:\n",
    "        result = 0.0\n",
    "\n",
    "      if result > 0:\n",
    "        prices.append(result)\n",
    "        weights.append(probability)\n",
    "\n",
    "    if not prices:\n",
    "      return 0.0, 0.0\n",
    "\n",
    "    total = sum(weights)\n",
    "\n",
    "    weighted_prices = [price * weight / total for price, weight in zip(prices, weights)]\n",
    "\n",
    "    return sum(weighted_prices).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b38a675c-31e0-4538-aac3-8cbb3e31ff3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_GHfTwHXD5f",
    "outputId": "056b0fc2-5632-4be8-ee24-b6bcefe14ab9"
   },
   "outputs": [],
   "source": [
    "improved_model_predict(test[0][\"text\"], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a1d2d63-92a4-4ffd-a315-cea347e89e7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "W_KcLvyt6kbb",
    "outputId": "fba4200d-b911-467b-ab3c-17b78aa3b408"
   },
   "outputs": [],
   "source": [
    "Tester.test(improved_model_predict, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c65c9287-06cb-40d4-a7f1-2cff4fb2b77e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![image.png](attachment:0dcb25a7-83fa-4313-a94f-d3a56a0f07bc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fb364f7-8969-423e-bcd1-705b3e6347f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 400K Sample Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "992aaf62-c7c6-4982-8a08-ef6c5d901fbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "dd1b57e03f2641d3b702f2cc66942b8f",
      "e1d477dccbfc44a8a6da301486180e82",
      "c312a5111a284c3db88f22290869c023",
      "ce118d8b8146497f9c7fdd3b38188e72",
      "bc46c271637341bb82d6b87df22ab2af",
      "602adf3242f54731938b68d3cf68465e",
      "39fae5e74834421795729a259a046fb8",
      "0618d8626e2e46cb9a17f86444de3c48",
      "1cd43b5b2fe445088c84e19773ad861e",
      "f70a29870ab34f34a1900b2df2bf177e",
      "41a96c5e35a44b898b872c189f531d3a",
      "0a524a73d5d6478db81256371bf2bc9b",
      "275f6179dc624bceaa5d0639fe0b1b00",
      "79c41b26746344bc9a220f2376360110",
      "287a6430766c44e5a71dda1048fa2a2c",
      "3bbe1a454a854747a96fe83e91d6cb3c",
      "8a93759afe21414fb0d6684f0a591d60",
      "a3d76b3ce67a495db861bac80cfc0864",
      "8fc794262ed14fc785c8f06e734c57d4",
      "7dc967baa0e7427bb66cf3e26849d508",
      "2d7a6dbd15304347a37dbfb6e5ec7203",
      "288393e05947444bad11034071015baf"
     ]
    },
    "id": "Kl6n_0sAbU0g",
    "outputId": "2fb53efb-da22-4c29-a594-c2cf5a079388"
   },
   "outputs": [],
   "source": [
    "FINETUNED_MODEL = \"ed-donner/pricer-2024-09-13_13.04.39\"\n",
    "REVISION = \"e8d637df551603dc86cd7a1598a8f44af4d7ae36\"\n",
    "fine_tuned_model = PeftModel.from_pretrained(base_model, FINETUNED_MODEL, revision=REVISION)\n",
    "print(f\"Memory footprint: {fine_tuned_model.get_memory_footprint() / 1e6:.1f} MB\")\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c49f3ff3-031e-4da7-91f5-4a3b724473a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "R0YlorBhbeSE",
    "outputId": "f42de9bf-d45a-4d2d-c218-fe000d716e54"
   },
   "outputs": [],
   "source": [
    "Tester.test(improved_model_predict, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "609428f3-29c5-4715-8d49-088692f2b4d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üéâ  And there it is ‚Äî the open-source, quantized, and fine-tuned model outperforms the rest. üôå \n",
    "\n",
    "üìò We'll continue in [the next notebook](https://github.com/lisekarimi/lexo/blob/main/09_part8_summary.ipynb) with a final wrap-up and summary of key insights.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "09_part7_eval_llama_qlora",
   "widgets": {}
  },
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
