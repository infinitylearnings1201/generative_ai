{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "723178ed-25d4-42cf-9e5e-0073cbd9dfb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "GHsssBgWM_l0"
   },
   "source": [
    "# üîç Predicting Item Prices from Descriptions (Part 8)\n",
    "---\n",
    "- Data Curation & Preprocessing\n",
    "- Model Benchmarking ‚Äì Traditional ML vs LLMs\n",
    "- E5 Embeddings & RAG\n",
    "- Fine-Tuning GPT-4o Mini\n",
    "- Evaluating LLaMA 3.1 8B Quantized\n",
    "- Fine-Tuning LLaMA 3.1 with QLoRA\n",
    "- Evaluating Fine-Tuned LLaMA\n",
    "- ‚û°Ô∏è Summary & Leaderboard\n",
    "\n",
    "---\n",
    "\n",
    "# üß™ Part 8: Summary & Leaderboard\n",
    "\n",
    "![](https://github.com/lisekarimi/lexo/blob/main/assets/09_ft_leaderboard.png?raw=true)\n",
    "\n",
    "# ü•á The winner is the LLaMA 3.1 8B (4-bit) fine-tuned on 400K samples \n",
    "\n",
    "LLaMA 3.1 8B (4-bit) fine-tuned on 400K samples is outperforming even the big guy GPT-4o  ‚Äî with the lowest error and highest accuracy (75.6%).\n",
    "\n",
    "RAG + GPT-4o Mini also did well, proving that retrieval adds real value.\n",
    "\n",
    "On the other hand, traditional ML models and even human guesses, gave weaker results and fell behind the top models.\n",
    "\n",
    "üí° As we‚Äôve seen, a **well-tuned open-source small model** can do amazing things on a focused task ‚Äî sometimes even better than large, closed models.\n",
    "It‚Äôs not about size ‚Äî it‚Äôs about fit, focus, and fine-tuning.\n",
    "\n",
    "# ‚ú® Conclusion\n",
    "What a journey! From classic ML to state-of-the-art LLMs, from embeddings to retrieval and fine-tuning ‚Äî we explored it all to answer: who predicts prices best?\n",
    "\n",
    "Thanks for following along ‚Äî see you in the next challenge! üöÄ\n",
    "\n",
    "---\n",
    "üì¢ Find more LLM notebooks on my [GitHub repository](https://github.com/lisekarimi/lexo)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "09_part8_summary",
   "widgets": {}
  },
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
