{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13191a0a-6a23-41d1-a1a8-ba7c6ab7472f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üîç Predicting Item Prices from Descriptions (Part 2)\n",
    "---\n",
    "- Data Curation & Preprocessing\n",
    "- ‚û°Ô∏è Model Benchmarking ‚Äì Traditional ML vs LLMs\n",
    "- E5 Embeddings & RAG\n",
    "- Fine-Tuning GPT-4o Mini\n",
    "- Evaluating LLaMA 3.1 8B Quantized\n",
    "- Fine-Tuning LLaMA 3.1 with QLoRA\n",
    "- Evaluating Fine-Tuned LLaMA \n",
    "- Summary & Leaderboard\n",
    "\n",
    "--- \n",
    "\n",
    "# ‚öîÔ∏è Part 2: Traditional ML vs LLMs\n",
    "\n",
    "- Tasks:\n",
    "    - Vectorize text (BoW, Word2Vec)\n",
    "    - Train SVR, LR, XGBoost models\n",
    "    - Predict with LLMs (GPT-4o, Claude, LLaMA‚Ä¶)\n",
    "    - Compare traditional ML vs LLMs\n",
    "  \n",
    "üìä Which model predicts prices best? Let‚Äôs find out.\n",
    "\n",
    "- üßë‚Äçüíª Skill Level: Advanced\n",
    "- ‚öôÔ∏è Hardware: ‚úÖ CPU is sufficient ‚Äî no GPU required\n",
    "- üõ†Ô∏è Requirements: üîë HF Token, Open API Key, Anthropic API key, Groq API key\n",
    "\n",
    "‚ö†Ô∏è This notebook assumes you're familiar with NLP techniques (e.g., converting text to vectors using Bag-of-Words or Word2Vec) and traditional ML models (like SVR, Logistic Regression, XGBoost) along with basic evaluation metrics.\n",
    "\n",
    "---\n",
    "üì¢ Find more LLM notebooks on my [GitHub repository](https://github.com/lisekarimi/lexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63dbb9d1-d3af-4a07-bdb0-b80c8fb15870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import re\n",
    "import csv\n",
    "import tiktoken\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.svm import LinearSVR\n",
    "import xgboost as xgb\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31c11df7-8572-49cf-97be-ca706df20913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üì• Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67e23c0a-7e61-41dc-9cf4-84e5d42ac7eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #If you face NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported run:\n",
    "# %pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78884e53-b839-443e-bbc4-0c4b066da353",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "HF_USER = \"lisekarimi\"\n",
    "DATASET_NAME = f\"{HF_USER}/pricer-data\"\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "train = dataset['train']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c44893d-d5ae-4818-a873-944b3524390c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(train[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41264b15-33c7-41f4-b301-1b977069b8ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(train[0][\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a25136e-e2fa-42c8-a410-256d68f3db20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üõ†Ô∏è Prepare Data for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fa28d30-56da-4215-955b-d3a451f35502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def mask_price_value(text):\n",
    "    return re.sub(r\"(\\n\\nPrice is \\$).*\", r\"\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a487a18c-8548-4ddc-b9ce-1f50109f0915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract prices\n",
    "prices = np.array([float(datapoint[\"price\"]) for datapoint in train])\n",
    "\n",
    "# Extract cleaned prompts\n",
    "documents = [mask_price_value(datapoint[\"text\"]) for datapoint in train]\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8be4dc87-9685-404f-9247-d741d44c926f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fd107d1-1a1f-4379-9c9b-814f773bd7d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìä Model Evaluation with testing.py\n",
    "\n",
    "- Runs predictions and computes errors on test data\n",
    "- Metrics: Absolute error, RMSLE, and hit rate\n",
    "- Visual: Scatter plot of predicted vs. actual prices (color-coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34c23a30-0da0-48d6-a16e-c62f405be259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import helpers.testing\n",
    "importlib.reload(helpers.testing)\n",
    "\n",
    "from helpers.testing import Tester  # noqa: E402\n",
    "\n",
    "results = {}  # Store each model's tester to compare and find the best performer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98f67801-3d60-4b56-ab9a-88b4716e1270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üéØ Price Prediction with Traditional ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5d7bc02-d5de-4c6d-b0aa-c629a4417d95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bag-of-Words + Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d53c48b7-db12-4213-86a3-d164458112e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the CountVectorizer for a Bag of Words model\n",
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, prices)\n",
    "\n",
    "def bow_lr_pricer(datapoint):\n",
    "    x = vectorizer.transform([mask_price_value(datapoint[\"text\"])])\n",
    "    return max(regressor.predict(x)[0], 0)\n",
    "\n",
    "tester = Tester(bow_lr_pricer, test)\n",
    "tester.run()\n",
    "results[\"Bag of Words LR\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf3bfb06-ffcb-44f7-af95-d82291870f66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Bow Lr Pricer Error=$121.23 RMSLE=0.98 Hits=27.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a61474ba-eacb-4b86-9159-5acf4f403747",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Word2Vec + Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "228e2116-65e9-4249-89ab-e3f632810447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the documents\n",
    "processed_docs = [simple_preprocess(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=processed_docs, vector_size=400, window=5, min_count=1, workers=4)\n",
    "\n",
    "# This step of averaging vectors across the document is a weakness in our approach\n",
    "\n",
    "def document_vector(doc):\n",
    "    doc_words = simple_preprocess(doc)\n",
    "    word_vectors = [w2v_model.wv[word] for word in doc_words if word in w2v_model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(w2v_model.vector_size)\n",
    "\n",
    "# Create feature matrix\n",
    "X_w2v = np.array([document_vector(doc) for doc in documents])\n",
    "\n",
    "# Run Linear Regression on word2vec\n",
    "\n",
    "word2vec_lr_regressor = LinearRegression()\n",
    "word2vec_lr_regressor.fit(X_w2v, prices)\n",
    "\n",
    "def word2vec_lr_pricer(datapoint):\n",
    "    doc = mask_price_value(datapoint[\"text\"])\n",
    "    vec = document_vector(doc)\n",
    "    return max(0, word2vec_lr_regressor.predict([vec])[0])\n",
    "\n",
    "tester = Tester(word2vec_lr_pricer, test)\n",
    "tester.run()\n",
    "results[\"Word2Vec LR\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94e8c2fa-754b-47fc-b214-9641e3123452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Word2Vec Lr Pricer Error=$127.42 RMSLE=0.97 Hits=27.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fa34b50-a3a8-4676-a323-543d907d6e1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Word2Vec + Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e36bef80-734e-4e2f-9069-09489ff67bc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "svr_regressor = LinearSVR()\n",
    "svr_regressor.fit(X_w2v, prices)\n",
    "\n",
    "def svr_pricer(datapoint):\n",
    "    np.random.seed(42)\n",
    "    doc = mask_price_value(datapoint[\"text\"])\n",
    "    doc_vector = document_vector(doc)\n",
    "    return max(float(svr_regressor.predict([doc_vector])[0]),0)\n",
    "\n",
    "tester = Tester(svr_pricer, test)\n",
    "tester.run()\n",
    "results[\"Word2Vec SVR\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b9b4f86-1011-4015-be29-b690c84a1ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Svr Pricer Error=$124.24 RMSLE=0.98 Hits=28.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "495ce75c-c191-4a01-9856-18b757dc9166",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Word2Vec + XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1992749-cadd-4faa-ba88-8a2dddef37d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I initially tried Random Forest, but it struggled with high training time and didn‚Äôt scale well with this data.\n",
    "That‚Äôs why I opted for XGBoost ‚Äî it‚Äôs faster, handles large datasets efficiently, and often delivers better performance on structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61d275c0-2e06-4643-9da2-d25b70419ae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "xgb_model.fit(X_w2v, prices)\n",
    "\n",
    "def xgboost_pricer(datapoint):\n",
    "    doc = mask_price_value(datapoint[\"text\"])\n",
    "    doc_vector = document_vector(doc)\n",
    "    return max(0, xgb_model.predict([doc_vector])[0])\n",
    "\n",
    "tester = Tester(xgboost_pricer, test)\n",
    "tester.run()\n",
    "results[\"Word2Vec XGBoost\"] = tester\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd19c3c5-0b62-4d59-b6c5-2b0222fd0937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Xgboost Pricer Error=$107.97 RMSLE=0.84 Hits=29.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bed17bae-0cb2-40c0-9117-2e887313239e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üöÄ Price Prediction with Frontier LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c35eac2-4988-4bb0-b1b6-2c35ee0dfda6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# Get API keys from environment\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "   print(\"‚ùå OPENAI_API_KEY is missing\")\n",
    "\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_api_key:\n",
    "   print(\"‚ùå ANTHROPIC_API_KEY is missing\")\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "if not groq_api_key:\n",
    "   print(\"‚ùå GROQ_API_KEY is missing\")\n",
    "\n",
    "# Initialize clients\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "claude = Anthropic(api_key=anthropic_api_key)\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86d388b4-07f2-4451-babf-27aa87a48e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def messages_for(datapoint):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = mask_price_value(datapoint[\"text\"]).replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]\n",
    "\n",
    "messages_for(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f4ccca3-bb3c-42c3-b9ad-cbe6fb393b17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# A utility function to extract the price from a string\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0\n",
    "\n",
    "get_price(\"The price is roughly $99.99 because blah blah\") # Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99ad98f9-e45d-4cfd-9c1b-3596866a7ea3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# A utility function to Count the tokens before passing the prompt to the model\n",
    "\n",
    "def count_tokens(messages):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    token_count = sum(len(encoding.encode(message['content'])) for message in messages)\n",
    "    return token_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe9b7c91-cd95-44a7-8c45-8c5f462da91d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f30f4038-0466-47c9-9aef-244581b088b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count tokens once before running\n",
    "total_tokens = 0\n",
    "for datapoint in train:\n",
    "    messages = messages_for(datapoint)\n",
    "    total_tokens += count_tokens(messages)\n",
    "print(f\"Total tokens: {total_tokens}\")\n",
    "\n",
    "def gpt_4o_mini(datapoint):\n",
    "    messages = messages_for(datapoint)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        seed=42,\n",
    "        max_tokens=5\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)\n",
    "\n",
    "tester = Tester(gpt_4o_mini, test)\n",
    "tester.run()\n",
    "results[\"gpt 4o mini\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cd30884-78b2-44a6-9311-fa809a27d730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gpt 4o Mini Error=$99.30 RMSLE=0.75 Hits=44.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00f3bd2a-ae49-417e-a365-d4da5ff6e0e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### gpt 4o (the big guy üòé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe731f75-838a-4e29-89a4-93b838d7c5fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gpt_4o_frontier(datapoint):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages_for(datapoint),\n",
    "        seed=42,\n",
    "        max_tokens=5\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)\n",
    "\n",
    "tester = Tester(gpt_4o_frontier, test)\n",
    "tester.run()\n",
    "results[\"gpt 4o (the big guy)\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29b92e31-df72-479b-a2a8-6e112db32e6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gpt 4O Frontier Error=$87.68 RMSLE=1.01 Hits=51.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15310d04-c2b4-432c-aa19-27069fc9f468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### claude 3.7 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "302c5a0e-113e-451a-afa4-f0810751d5ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def claude_3_point_7_sonnet(datapoint):\n",
    "    messages = messages_for(datapoint)\n",
    "    system_message = messages[0]['content']\n",
    "    messages = messages[1:]\n",
    "    response = claude.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=5,\n",
    "        system=system_message,\n",
    "        messages=messages\n",
    "    )\n",
    "    reply = response.content[0].text\n",
    "    return get_price(reply)\n",
    "\n",
    "tester = Tester(claude_3_point_7_sonnet, test)\n",
    "tester.run()\n",
    "results[\"claude 3.7 sonnet\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "592337ea-5c25-4ae7-9527-840c01db8480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Claude 3 Point 7 Sonnet Error=$110.26 RMSLE=0.60 Hits=46.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef0409b7-009d-4b12-b241-ba8d7b6505cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### groq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a20cc63e-4b81-4dab-9e87-68d5a8134269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def llama3_groq_pricer(datapoint):\n",
    "    response = groq.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=messages_for(datapoint),\n",
    "        max_tokens=5,\n",
    "        seed=42\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)\n",
    "\n",
    "tester = Tester(llama3_groq_pricer, test)\n",
    "tester.run()\n",
    "results[\"llama3-70b-8192\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7e46dcd-811b-4c78-a772-9aafcfe5bdf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Llama3 Groq Pricer Error=$122.95 RMSLE=0.73 Hits=44.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "835c95a5-06e0-4ced-aeb8-83c38aad2e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def deepseek_qwen_pricer(datapoint):\n",
    "    response = groq.chat.completions.create(\n",
    "        model=\"deepseek-r1-distill-qwen-32b\",\n",
    "        messages=messages_for(datapoint),\n",
    "        max_tokens=5,\n",
    "        seed=42\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)\n",
    "\n",
    "tester = Tester(deepseek_qwen_pricer, test)\n",
    "tester.run()\n",
    "results[\"deepseek-qwen-32b\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c69ee1a-f17d-4ac8-b010-025792102e3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Deepseek Qwen Pricer Error=$178.96 RMSLE=0.83 Hits=33.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "899bd3f5-241b-4458-9b73-d58551283e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üïµÔ∏è Human Judgement Baseline (Ed)\n",
    "\n",
    "We include a human baseline from our instructor Ed, who manually estimated prices based on item descriptions (üí™ thanks Ed for taking on this exhausting task!). This allows us to compare model performance against human intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d5145c3-4b33-4696-ace3-78121a25f00c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "human_predictions = []\n",
    "\n",
    "with open('data/human_output.csv', 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        human_predictions.append(float(row[1]))\n",
    "\n",
    "def human_pricer(datapoint):\n",
    "    # `Tester` runs in order, so use the index from Tester itself\n",
    "    idx = human_pricer.counter\n",
    "    human_pricer.counter += 1\n",
    "    return human_predictions[idx]\n",
    "\n",
    "human_pricer.counter = 0  # initialize counter\n",
    "\n",
    "tester = Tester(human_pricer, test)\n",
    "tester.run()\n",
    "results[\"Human Predictions\"] = tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e400156-3ce4-4658-a647-5f1663a15fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ü•á Benchmark Showdown: ML, LLMs, and Ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33fd2446-d8e6-4040-86fb-80193463935d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def truncate(x, decimals=2):\n",
    "    factor = 10 ** decimals\n",
    "    return math.floor(x * factor) / factor\n",
    "\n",
    "df_results = []\n",
    "\n",
    "for model_name, tester in results.items():\n",
    "    avg_error = truncate(sum(tester.errors) / tester.size)\n",
    "    hit_percent = truncate(sum(1 for c in tester.colors if c == \"green\") / tester.size * 100)\n",
    "    rmsle = truncate(math.sqrt(sum(tester.sles) / tester.size))\n",
    "\n",
    "    df_results.append({\n",
    "        \"model\": model_name,\n",
    "        \"avrg_error\": avg_error,\n",
    "        \"rmsle\": rmsle,\n",
    "        \"accuracy_%\": hit_percent\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(df_results)\n",
    "df_results = df_results.sort_values(by=\"avrg_error\")\n",
    "\n",
    "# Display with .2f formatting\n",
    "print(df_results.to_string(index=False, float_format=\"{:.2f}\".format))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3ca595d-5c2d-4eb0-a15d-9fdb842251c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "üèÅ **GPT-4o, GPT-4o Mini and XGBoost** clearly outperformed both LLMs (like Claude 3.7, LLaMA3-70B, DeepSeek-32B) and traditional ML approaches (LR, SVR).\n",
    "\n",
    "Now let‚Äôs take the top-performing frontier LLM ‚Äî **GPT-4o Mini** ‚Äî to test if retrieval (RAG) boosts its performance, and the best ML model ‚Äî **XGBoost** ‚Äî to see if contextual embeddings enhance its predictions.\n",
    "\n",
    "Let‚Äôs find out.\n",
    "\n",
    "üîú See you in the [next notebook](https://github.com/lisek75/nlp_llms_notebook/blob/main/09_part3_e5embeddings_rag.ipynb)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "09_part2_tradml_vs_frontier",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
