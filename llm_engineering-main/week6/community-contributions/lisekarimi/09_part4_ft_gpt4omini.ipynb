{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd4edf25-1db7-4774-b52a-23378c099695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üîç Predicting Item Prices from Descriptions (Part 4)\n",
    "---\n",
    "-  Data Curation & Preprocessing\n",
    "- Model Benchmarking ‚Äì Traditional ML vs LLMs\n",
    "- E5 Embeddings & RAG\n",
    "- ‚û°Ô∏è Fine-Tuning GPT-4o Mini\n",
    "- Evaluating LLaMA 3.1 8B Quantized\n",
    "- Fine-Tuning LLaMA 3.1 with QLoRA\n",
    "- Evaluating Fine-Tuned LLaMA\n",
    "- Summary & Leaderboard\n",
    "\n",
    "---\n",
    "\n",
    "# üîß Part 4: Fine-Tuning GPT-4o Mini\n",
    "\n",
    "- üßë‚Äçüíª Skill Level: Advanced\n",
    "- ‚öôÔ∏è Hardware: ‚úÖ CPU is sufficient ‚Äî no GPU required\n",
    "- üõ†Ô∏è Requirements: üîë HF Token, Open API Key, wandb API Key\n",
    "- Tasks:\n",
    "    - Convert chat data to .jsonl format for OpenAI\n",
    "    - Fine-tune the model and monitor with Weights & Biases\n",
    "    - Test the fine-tuned GPT-4o Mini \n",
    "\n",
    "Can fine-tuning GPT-4o Mini outperform both its zero-shot baseline and RAG-enhanced version?  \n",
    "Time to find out.\n",
    "\n",
    "---\n",
    "üì¢ Find more LLM notebooks on my [GitHub repository](https://github.com/lisekarimi/lexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07c5d876-fa47-4b62-870f-d8de36a1839f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "165833c0-5467-4e56-8f10-cbdbe6959338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "   print(\"‚ùå OPENAI_API_KEY is missing\")\n",
    "\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "if not hf_token:\n",
    "   print(\"‚ùå HF_TOKEN is missing\")\n",
    "\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62cebd3c-3869-4278-976b-291e11c4cba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üì• Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cccd47ce-4a8c-454e-9444-0f5aa8a1c81c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #If you face NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported run:\n",
    "# %pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b14aaca-02cb-4c47-a591-160893177810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "HF_USER = \"lisekarimi\"\n",
    "DATASET_NAME = f\"{HF_USER}/pricer-data\"\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "train = dataset['train']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4395dc1c-2ac7-4720-a097-72d4a33ea9a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1598f139-8367-4de7-90fe-1225717552ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üõ†Ô∏è Step 1 : Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f715421-499d-4622-bd34-cabf93d73fa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To fine-tune GPT-4o-mini, OpenAI requires training data in **.jsonl format**. \n",
    "\n",
    "`make_jsonl` converts our chat data :\n",
    "\n",
    "from \n",
    "\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"You estimate prices of items. Reply only with the price, no explanation\"},\n",
    "  {\"role\": \"user\", \"content\": \"How much is this laptop worth?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Price is $999.00\"}\n",
    "]\n",
    "\n",
    "into the .jsonl format \n",
    "\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You estimate prices of items. Reply only with the price, no explanation\"}, {\"role\": \"user\", \"content\": \"How much is this laptop worth?\"}, {\"role\": \"assistant\", \"content\": \"Price is $999.00\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "189c2f4e-54e2-437e-aea3-77cb19face9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mask the price in the test item\n",
    "def mask_price_value(text):\n",
    "    return re.sub(r\"(\\n\\nPrice is \\$).*\", r\"\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61c287cf-ade3-4a6a-be36-cfae375045c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def messages_for(datapoint):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = mask_price_value(datapoint[\"text\"]).replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    assistant_response = f\"Price is ${datapoint['price']:.2f}\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_response}\n",
    "    ]\n",
    "\n",
    "messages_for(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ec5d165-b8d3-414f-b6c2-4cfc2880bf1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_jsonl(datapoints):\n",
    "    result = \"\"\n",
    "    for datapoint in datapoints:\n",
    "        messages = messages_for(datapoint)\n",
    "        messages_str = json.dumps(messages, ensure_ascii=False)\n",
    "        result += '{\"messages\": ' + messages_str + '}\\n'\n",
    "    return result.strip()\n",
    "\n",
    "make_jsonl(train.select([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9e323f4-35f5-4092-859a-031de6160f18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_train = train.select(range(100))\n",
    "ft_validation = train.select(range(100, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "370b1bd3-dbad-4060-972c-98ba65437b90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the items into jsonl and write them to a file\n",
    "\n",
    "def write_jsonl(datapoints, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        jsonl = make_jsonl(datapoints)\n",
    "        f.write(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28e185a7-2e76-4789-b91c-e35fdfec49de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "write_jsonl(ft_train, \"data/ft_train.jsonl\")\n",
    "write_jsonl(ft_validation, \"data/ft_val.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d997eee-04ea-4cca-961e-dea2894b6bf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/ft_train.jsonl\", \"rb\") as f:\n",
    "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")\n",
    "with open(\"data/ft_val.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0ea4998-0221-49b8-bfaf-8ba01441f8f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9a3bf53-a3f1-4d1a-961e-2f50d24bcf9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "validation_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff19e996-10ed-4207-8607-53b98e1b02ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üöÄ Step 2: Run Fine-Tuning & Monitor with wandb\n",
    "We will use https://wandb.ai to monitor the training runs\n",
    "\n",
    "1- Create an API key in wandb\n",
    "\n",
    "2- Add this key in OpenAI dashboard https://platform.openai.com/account/organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e7f3988-b9ef-4e9c-a505-a7a31604109d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wandb_integration = {\"type\": \"wandb\", \"wandb\": {\"project\": \"gpt-pricer\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca08ba30-cc46-4a97-9d13-c915c7608c4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run the fine tuning\n",
    "\n",
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    seed=42,\n",
    "    hyperparameters={\"n_epochs\": 1},\n",
    "    integrations = [wandb_integration],\n",
    "    suffix=\"pricer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a9f53e3-0009-4732-ab6d-dc4c48ad0886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "job_id = openai.fine_tuning.jobs.list(limit=1).data[0].id\n",
    "job_id\n",
    "\n",
    "# Then check your wandb dashboard to view the run of this job ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "290c36d2-c84c-400f-8e98-25582b83f945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use this command to track the fine-tuning progress here\n",
    "\n",
    "openai.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=2).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e619252a-27ad-4bd1-a89c-cfe3ac53d78d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìß You‚Äôll get an email once fine-tuning is complete. ‚òï You can take a break until then. ‚ñ∂Ô∏è Once you receive it, run the cells below to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfc22f90-6125-4104-b6ca-a70fda38c526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3 : Test the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19b0d1e1-c79b-4525-ad18-027327339ef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_model_name = openai.fine_tuning.jobs.retrieve(job_id).fine_tuned_model\n",
    "ft_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "934a96b1-2f91-4d9c-9925-06e832b489ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can find the entire fine-tuning process in the **Fine-tuning** dashboard on OpenAI.\n",
    "\n",
    "![Fine-tuning Process](https://github.com/lisekarimi/lexo/blob/main/assets/09_ft_gpt4omini.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0ce76ac-aae9-490d-a841-5e6321dacf5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build LLM messages\n",
    "def build_messages(datapoint):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = mask_price_value(datapoint[\"text\"]).replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0\n",
    "\n",
    "def gpt_ft(datapoint):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=ft_model_name,\n",
    "        messages=build_messages(datapoint),\n",
    "        seed=42,\n",
    "        max_tokens=7\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad581335-5f91-4fbe-9dd8-e2c88dffdd80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(test[0][\"price\"])\n",
    "print(gpt_ft(test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bb20fff-acff-464c-b9e7-0bd51e388559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üîî **Reminder:**  \n",
    "- In **Part 2**, GPT-4o Mini (zero-shot) scored:  \n",
    "  Avg. Error: ~$99 | RMSLE: 0.75 | Accuracy: 44.8%  \n",
    "\n",
    "- In **Part 3**, with **RAG**, performance improved to:  \n",
    "  Avg. Error: ~$59.54 | RMSLE: 0.42 | Accuracy: 69.2%\n",
    "\n",
    "üß™ **Now it‚Äôs time to see** if fine-tuning can push GPT-4o Mini even further and outperform both baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79a4eefd-170d-4269-82e6-26ccc27814ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import helpers.testing\n",
    "importlib.reload(helpers.testing)\n",
    "\n",
    "from helpers.testing import Tester  # noqa: E402\n",
    "\n",
    "tester = Tester(gpt_ft, test)\n",
    "tester.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eb142da-7173-4c9f-bb89-2683d8adade6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gpt Ft Error=$129.16 RMSLE=0.94 Hits=35.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e09e98e3-2c7a-4f6d-8bd1-2105809707a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Fine-tuning GPT-4o Mini led to worse performance than both its zero-shot and RAG-enhanced versions.**\n",
    "\n",
    "‚ö†Ô∏è When Fine-Tuning Isn‚Äôt Needed:\n",
    "- For tasks like price prediction, GPT-4o performs well with prompting alone ‚Äî thanks to strong pretraining and generalization.\n",
    "- üí° Fine-tuning isn‚Äôt always better. Use it when prompting fails ‚Äî not by default.\n",
    "\n",
    "‚úÖ **When Fine-Tuning Is Worth It (based on OpenAI‚Äôs own guidelines)**\n",
    "- Custom tone/style ‚Äì e.g., mimicking a brand voice or writing like a specific author\n",
    "- More consistent output ‚Äì e.g., always following a strict format\n",
    "- Fix prompt failures ‚Äì e.g., when multi-step instructions get ignored\n",
    "- Handle edge cases ‚Äì e.g., rare product types or weird inputs\n",
    "- Teach new tasks ‚Äì e.g., estimating prices in a custom format no model has seen before\n",
    "\n",
    "---\n",
    "\n",
    "Now that we‚Äôve explored both frontier closed-source models and traditional ML, it‚Äôs time to turn to open-source.\n",
    "\n",
    "üöÄ **Next up: Fine-tuned LLaMA 3.1 8B (quantized)** ‚Äî can it beat its base version, outperform GPT-4o Mini, or even challenge the big players?\n",
    "\n",
    "üîç Let‚Äôs find out in the [next notebook](https://github.com/lisekarimi/lexo/blob/main/09_part5_llama31_8b_quant.ipynb)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "09_part4_ft_gpt4omini",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
