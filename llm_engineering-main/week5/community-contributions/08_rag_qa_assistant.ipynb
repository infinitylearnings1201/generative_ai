{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "857ad60c-114a-41c4-8c52-20265f6fea41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# RAG-powered Q&A agent for Insurellm employees\n",
    "---\n",
    "\n",
    "An internal expert knowledge assistant for Insurellm employees, using Retrieval-Augmented Generation (RAG) to deliver fast, accurate, and cost-efficient answers to a wide range of internal queries,\n",
    "\n",
    "- üåç Task: Answer questions about Insurellm using naive RAG\n",
    "- üß† Models: OpenAI GPT via LangChain\n",
    "- üîç Retrieval: ChromaDB + OpenAI embeddings\n",
    "- üöÄ Tools:\n",
    "    - langchain: 0.3.21\n",
    "    - openai: 1.69.0\n",
    "    - chromadb: 0.6.3\n",
    "    - gradio: 5.23.1\n",
    "    - python: 3.11.11\n",
    "\n",
    "- ‚ú® Features:\n",
    "\n",
    "    - Loads PDF, text, and markdown files automatically\n",
    "    - Only updates when files actually change (saves time)\n",
    "    - Breaks documents into small, overlapping pieces for better search\n",
    "    - Finds the most relevant information using smart matching\n",
    "    - Remembers conversation history and shows where answers come from\n",
    "    - Only answers based on your documents (no made-up information\n",
    "    - Web chat interface with streaming responses\n",
    "    - Handles errors gracefully and detects duplicate content\n",
    "    - Tracks document details and keeps everything organized\n",
    "    - Ready for business use with built-in quality checks\n",
    "\n",
    "- üì§ Output: Streaming response with sources retrieved from the knowledge base\n",
    "- üßë‚Äçüíª Skill Level: Intermediate\n",
    "- ‚öôÔ∏è Hardware: ‚úÖ CPU is sufficient ‚Äî no GPU required\n",
    "\n",
    "üõ†Ô∏è **Requirements**: üîë OpenAI API Key \n",
    "\n",
    "‚öôÔ∏è **Customizable by user**\n",
    "- üìù Modify system and expansion prompts\n",
    "- üìÅ Drop in new company documents\n",
    "- üéØ Adjust retrieval top-k and similarity threshold\n",
    "\n",
    "This project currently uses a naive RAG approach, which limits the assistant's performance and accuracy. To improve response quality and reliability, more advanced RAG techniques will be needed ‚Äî a more refined and powerful version is planned for future release.\n",
    "\n",
    "![](https://github.com/lisekarimi/lexo/blob/main/assets/08_naive_rag.png?raw=true)\n",
    "\n",
    "---\n",
    "üì¢ Find more LLM notebooks on my [GitHub repository](https://github.com/lisekarimi/lexo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7d0a320-f12b-45a9-be9b-0c9caf88e799",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üì• Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8db118d1-42d2-4f4f-a3e5-37262accf9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import Field\n",
    "from sklearn.manifold import TSNE\n",
    "import gradio as gr\n",
    "\n",
    "# LangChain core imports\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from langchain.schema.vectorstore import VectorStoreRetriever\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# LangChain integrations\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5916f03-f555-40d6-aa11-e24c6d00d346",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîê Load env variables and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42b14695-6178-40af-b4ad-1a2e511807be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"data/knowledge-base/\" # Use your path\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "CHROMA_PATH = \"vector_db/chroma_insurellm\"\n",
    "\n",
    "# Explicitly access the OpenAI API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai_api_key:\n",
    "    print(\"‚ùå OPENAI_API_KEY is missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fcd164b-4ecf-461c-86ce-5d57f61bd6c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìÑ Load files as Document objects into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3269d007-8ce1-4859-9e97-ca1fe5471be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load .pdf, .txt, and .md documents with metadata, excluding Jupyter checkpoints.\n",
    "\n",
    "documents = []\n",
    "\n",
    "def add_metadata(doc, file_path):\n",
    "    doc.metadata[\"doc_type\"] = file_path.parent.name\n",
    "    doc.metadata[\"file_name\"] = file_path.name\n",
    "    if not doc.page_content.strip():\n",
    "        print(f\"‚ö†Ô∏è Empty content in {file_path}\")\n",
    "    # else:\n",
    "    #     print(doc)\n",
    "    #     print(\"-\" * 40)\n",
    "    return doc\n",
    "\n",
    "for file_path in Path(DATA_PATH).rglob(\"*\"):\n",
    "    if \".ipynb_checkpoints\" in file_path.parts:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        if file_path.name.endswith(\".pdf\"):\n",
    "            docs = PyPDFLoader(str(file_path)).load()\n",
    "        elif file_path.name.endswith((\".txt\", \".md\")):\n",
    "            docs = TextLoader(str(file_path), encoding=\"utf-8\").load()\n",
    "        else:\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Skipped {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    documents.extend([add_metadata(doc, file_path) for doc in docs])\n",
    "\n",
    "print(f\"{len(documents)} documents loaded.\" if documents else \"No documents loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "404bc5b9-c07e-4302-942e-126052a14764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÇÔ∏è Splitting documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7989a8ac-8fef-4480-9bf9-ae0819849b71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split documents into smaller chunks with overlapping characters for better context.\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True  # Maintain chunk order (useful for context tracking)\n",
    ")\n",
    "\n",
    "# Load and split documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "def generate_chunk_id(text):\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# Add chunk_id to each chunk's metadata\n",
    "for chunk in chunks:\n",
    "    chunk.metadata[\"chunk_id\"] = generate_chunk_id(chunk.page_content) # Create an MD5 hash of the chunk's content\n",
    "    if not chunk.page_content.strip():\n",
    "        print(f\"‚ö†Ô∏è Empty chunk from: {chunk.metadata['file_name']}\")\n",
    "\n",
    "# Debug: print a few chunk metadatas to verify chunk_id is added\n",
    "for i, chunk in enumerate(chunks[:2]):\n",
    "    print(f\"Chunk {i+1} metadata:\", chunk.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b490865-4831-4f79-b0a9-2d77c7041fbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicate chunk IDs\n",
    "chunk_ids = [chunk.metadata[\"chunk_id\"] for chunk in chunks]\n",
    "duplicate_ids = [chunk_id for chunk_id in chunk_ids if chunk_ids.count(chunk_id) > 1]\n",
    "\n",
    "if duplicate_ids:\n",
    "    print(f\"Duplicate chunk IDs found: {duplicate_ids}\")\n",
    "else:\n",
    "    print(\"No duplicate chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e14c1e4-7d3e-4007-9a8d-f7bdd9e9fdd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß† Chuncks Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7092e67d-7521-4800-87bb-b5b7c1510670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings()\n",
    "# By default, OpenAIEmbeddings() uses OpenAI's text-embedding-ada-002 model - a multilingual model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da1584dc-d701-4769-8ec0-90d6b54dcd27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üíæ Save embedded chunks to Chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6545e5e-1755-42ca-9dd0-1aaaf244fc00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(CHROMA_PATH, exist_ok=True)\n",
    "\n",
    "def get_existing_chunk_ids(db_path):\n",
    "    try:\n",
    "        db_existing = Chroma(persist_directory=db_path)\n",
    "        results = db_existing._collection.get(include=[\"metadatas\"])\n",
    "        return set(\n",
    "            m[\"chunk_id\"] for m in results[\"metadatas\"]\n",
    "            if isinstance(m, dict) and \"chunk_id\" in m\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error loading existing chunk IDs:\", e)\n",
    "        return set()\n",
    "\n",
    "# Get chunk_ids of current chunks\n",
    "new_chunk_ids = set([chunk.metadata[\"chunk_id\"] for chunk in chunks])\n",
    "\n",
    "# Get existing chunk_ids from Chroma\n",
    "existing_chunk_ids = get_existing_chunk_ids(CHROMA_PATH)\n",
    "\n",
    "# Compare\n",
    "if new_chunk_ids != existing_chunk_ids:\n",
    "    print(\"Chunk changes detected. Rebuilding Chroma DB.\")\n",
    "    db = Chroma.from_documents(documents=chunks, embedding=embedding_function, persist_directory=CHROMA_PATH)\n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "else:\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "    print(\"Chroma DB is up to date. Skipping regeneration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "447dd813-bf3c-4f4a-8897-28b55d62c6ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìä Visualizing the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbfbcc9c-d48e-409e-8f4e-28403af13393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection = db._collection\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue', '#4B0082', 'red', '#8B4513'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17c647ca-3000-4c1f-8a8e-6225f2a30680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=8, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    plot_bgcolor='black',\n",
    "    paper_bgcolor='black',\n",
    "    font=dict(color='black'),\n",
    "    xaxis=dict(gridcolor='lightgray', zerolinecolor='lightgray'),\n",
    "    yaxis=dict(gridcolor='lightgray', zerolinecolor='lightgray'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40),\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3eab3c9-c205-4744-a160-c02bb469c54f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e358876-2947-48c9-925a-bf716abe0d9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's try 3D!\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=8, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    plot_bgcolor='black',\n",
    "    paper_bgcolor='black',\n",
    "    font=dict(color='white'),\n",
    "    scene=dict(\n",
    "        xaxis=dict(color='white', backgroundcolor='black', showbackground=True),\n",
    "        yaxis=dict(color='white', backgroundcolor='black', showbackground=True),\n",
    "        zaxis=dict(color='white', backgroundcolor='black', showbackground=True)\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1316847c-8e38-4866-ad6f-ba43964972db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "395403c0-6a26-4cc5-bf71-b34ca9dff73d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîç Query Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a89b8643-3422-4fa3-ac43-5c67c3b7af9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "similarity_threshold = 0.5\n",
    "\n",
    "class MyVectorStoreRetriever(VectorStoreRetriever):\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        docs_and_similarities = (\n",
    "            self.vectorstore.similarity_search_with_relevance_scores(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Make the score part of the document metadata\n",
    "        for doc, similarity in docs_and_similarities:\n",
    "            doc.metadata[\"score\"] = similarity\n",
    "\n",
    "        docs = [doc for doc, sim in docs_and_similarities if sim >= self.search_kwargs.get(\"score_threshold\", 0)]\n",
    "        return docs\n",
    "\n",
    "retriever = MyVectorStoreRetriever(\n",
    "   vectorstore=db,\n",
    "   search_type=\"similarity_score_threshold\",\n",
    "   search_kwargs={\"score_threshold\": similarity_threshold, \"k\": 20},\n",
    ")\n",
    "\n",
    "\n",
    "# Add metadata to the context sentto the LLM\n",
    "def inject_metadata(doc: Document) -> Document:\n",
    "    doc_type = doc.metadata.get(\"doc_type\", \"Unknown\")\n",
    "    file_name = doc.metadata.get(\"file_name\", \"Unknown\")\n",
    "    content = f\"[SOURCE: {doc_type} - {file_name}]\\n{doc.page_content}\"\n",
    "    return Document(page_content=content, metadata=doc.metadata)\n",
    "\n",
    "class MetadataInjectingRetriever(BaseRetriever):\n",
    "    base_retriever: BaseRetriever = Field()\n",
    "\n",
    "    def _get_relevant_documents(self, query: str):\n",
    "        docs = self.base_retriever.get_relevant_documents(query)\n",
    "        return [inject_metadata(doc) for doc in docs]\n",
    "\n",
    "retriever = MetadataInjectingRetriever(base_retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c1f7d8c-3dc8-4b77-9696-ef86cb318cfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üó£Ô∏è LLM and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6697943-2543-475e-a532-a4dbf0f0f87e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b732884f-d887-41d3-ac4f-ff4c8427f5b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define your question\n",
    "question = \"Who are the top 3 earners in 2023 with base, bonus, and total. Include names.\"\n",
    "\n",
    "# Define the system prompt\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant that answers questions about the company Insurellm.\n",
    "\n",
    "Use the following chat history and retrieved documents to answer.\n",
    "\n",
    "Always base your answers strictly on the retrieved documents. If documents contain partial info, respond with what‚Äôs available. If there is no info, say so.\n",
    "\n",
    "Do not invent names, roles, or facts.\n",
    "\n",
    "You can use the document source information shown in the format [SOURCE: doc_type - file_name] if it helps you answer the question accurately.\n",
    "\n",
    "Always extract exact numbers (like number of employees, years, revenue, etc.) from the documents if they are mentioned.\n",
    "\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Documents:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"context\", \"question\"],\n",
    "    template=system_prompt\n",
    ")\n",
    "\n",
    "# Set up LLM, memory, and conversation chain\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key=\"answer\")\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# Format chat history\n",
    "chat_history_text = \"\\n\".join([f\"{msg.type.upper()}: {msg.content}\" for msg in memory.chat_memory.messages])\n",
    "\n",
    "# Retrieve docs using the original question\n",
    "retrieved_docs = retriever.get_relevant_documents(question)\n",
    "# print(\"\\nüì¶ Context sent to LLM:\\n\")\n",
    "# for i, doc in enumerate(retriever.get_relevant_documents(question), 1):\n",
    "#     print(f\"--- Document {i} ---\")\n",
    "#     print(doc.page_content)  # preview\n",
    "#     print()\n",
    "\n",
    "# Invoke the chain\n",
    "response = conversation_chain.invoke({\"question\": question})\n",
    "\n",
    "print(\"\\nüß† Answer:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daecc494-9d80-48d9-80e9-cca9aac08507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üéõÔ∏è Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "877bb845-46ca-43c7-8314-b0c2f9d78c5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Define your system prompt\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant that answers questions about the company Insurellm.\n",
    "\n",
    "Use the following chat history and retrieved documents to answer. Always base your answers strictly on the retrieved documents. If documents contain partial info, respond with what‚Äôs available. If there is no info, say so.\n",
    "\n",
    "You can use the document source information shown in the format [SOURCE: doc_type - file_name] if it helps answer the question accurately.\n",
    "\n",
    "Extract exact numbers (like number of employees, years, revenue, etc.) from the documents if mentioned. Do not invent names, roles, or facts.\n",
    "\n",
    "Behavior Guidelines:\n",
    "- Respond only when the user asks a question or requests clarification.\n",
    "- If the user greets you or expresses gratitude, respond warmly, but **avoid repeating the previous answer** unless explicitly requested for more details.\n",
    "- If the user asks \"thank you\" or similar, acknowledge it with gratitude, but **do not provide the same answer again** unless further information is requested.\n",
    "- If the user shares feedback, acknowledge it, thank them, and offer further assistance.\n",
    "- If the user expresses frustration or confusion, empathize, clarify, and offer further support.\n",
    "- If the user doesn't find a clear answer, encourage them to ask for clarification or provide additional details, and offer further assistance.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Documents:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b21102d-be82-4854-8b5a-ff0d614affb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Create the prompt template\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"context\", \"question\"],\n",
    "    template=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9be7f49b-4392-48e1-b793-f2997767fbcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Set up LLM, memory, retriever, and the updated chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key=\"answer\")\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    answer = \"\"\n",
    "    for chunk in result[\"answer\"]:\n",
    "        answer += chunk\n",
    "        yield answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4359a2a7-763c-4df9-9796-ec04f7d6918e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "08_rag_qa_assistant",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
