{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09ff767f-1519-43c9-a740-0687a9fbeb0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Weeks 2 - Day 2 - Gradio Chatbot with LiteLLM (Model Routing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "deee5cdc-4c4f-4bec-81af-74d979de9e85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Author** : [Marcus Rosen](https://github.com/MarcusRosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a01229fd-5b0b-4759-8cfb-4895e4e10d2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[LiteLLM](https://docs.litellm.ai/docs/) provides the abilitty to call different LLM providers via a unified interface, returning results in OpenAI compatible formats.\n",
    "\n",
    "Features:\n",
    "- Model Selection in Gradio (Anthropic, OpenAI, Gemini)\n",
    "- Single Inference function for all model providers via LiteLLM (call_llm)\n",
    "- Streaming **NOTE:** Bug when trying to stream in Gradio, but works directly in Notebook\n",
    "- Debug Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8723dc6f-132f-4899-9855-a6135d7e6614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6bd06ca-d349-43bb-9e45-1f61af9aff9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04ecb319-95a4-432b-8cbd-60f44adda46a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "   # import google.generativeai\n",
    "   # google.generativeai.configure()\n",
    "else:\n",
    "    print(\"Gemini API Key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f08f7f10-53d0-4ac8-a59c-7fef393cb590",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use LiteLLM to abstract out the model provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1d8593d-1559-43b9-923b-3a9ea77d6ecf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_llm(model, system_prompt, user_prompt, json_format_response=False, streaming=False):\n",
    "    if DEBUG_OUTPUT:    \n",
    "        print(\"call_llm()\")\n",
    "        print(f\"streaming={streaming}\")\n",
    "        print(f\"json_format_response={json_format_response}\")\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    # Use Json Reponse Format\n",
    "    # Link: https://docs.litellm.ai/docs/completion/json_mode\n",
    "    if json_format_response:\n",
    "        payload[\"response_format\"]: { \"type\": \"json_object\" }\n",
    "    \n",
    "    if streaming:\n",
    "        payload[\"stream\"] = True\n",
    "        response = completion(**payload)\n",
    "        # Return a generator expression instead of using yield in the function\n",
    "        return (part.choices[0].delta.content or \"\" for part in response)\n",
    "    else:\n",
    "        response = completion(**payload)\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c46bbcc-7030-4b03-b88a-b95c8d2d13ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Brochure building functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edcbf372-b976-438a-b3da-5b51b044f782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "305fa08f-d9d5-4b0a-8204-e54a38d11f16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_links(url, model):\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(\"get_links()\")\n",
    "    website = Website(url)\n",
    "\n",
    "    link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "    You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "    such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "    link_system_prompt += \"You should respond in raw JSON exactly as specified in this example. DO NOT USE MARKDOWN.\"\n",
    "    link_system_prompt += \"\"\"\n",
    "    {\n",
    "        \"links\": [\n",
    "            {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "            {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    result = call_llm(model=model, \n",
    "                      system_prompt=link_system_prompt, \n",
    "                      user_prompt=get_links_user_prompt(website), \n",
    "                      json_format_response=True, \n",
    "                      streaming=False)\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(result)\n",
    "    return json.loads(result)\n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(\"get_links_user_prompt()\")\n",
    "        \n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(user_prompt)\n",
    "    \n",
    "    return user_prompt\n",
    "\n",
    "def get_all_details(url, model):\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(\"get_all_details()\")\n",
    "        \n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url, model)\n",
    "    if DEBUG_OUTPUT:\n",
    "        print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result\n",
    "\n",
    "def get_brochure_user_prompt(company_name, url, model):\n",
    "    \n",
    "    if DEBUG_OUTPUT:\n",
    "        print(\"get_brochure_user_prompt()\")\n",
    "    \n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url, model)\n",
    "    user_prompt = user_prompt[:5000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ce5a9f5-1c2f-418f-831a-f702646d9e95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url, model, streaming):\n",
    "\n",
    "    system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "    if streaming:\n",
    "        result = call_llm(model=model, system_prompt=system_prompt, user_prompt=get_brochure_user_prompt(company_name, url, model), streaming=True)\n",
    "        return (p for p in result)\n",
    "    else:   \n",
    "        return call_llm(model=model, system_prompt=system_prompt, user_prompt=get_brochure_user_prompt(company_name, url, model), streaming=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db88da72-d115-4d1d-9c69-165726d49502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Testing Model before implenting Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c312172b-bb45-4b34-8e1a-dfe456ed384d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL=\"claude-3-haiku-20240307\"\n",
    "DEBUG_OUTPUT=False\n",
    "streaming=True\n",
    "result = create_brochure(company_name=\"Rio Tinto\", url=\"http://www.riotinto.com\", model=MODEL, streaming=streaming)\n",
    "\n",
    "if streaming:\n",
    "    for chunk in result:\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "else:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdc589d7-49c5-444a-b212-91c19f115067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Gradio Setup\n",
    "Associate Dropdown values with the model we want to use.\n",
    "Link: https://www.gradio.app/docs/gradio/dropdown#initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac9e56d7-164d-4457-a1c9-00f0b89977e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEBUG_OUTPUT=True\n",
    "view = gr.Interface(\n",
    "    fn=create_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown(choices=[(\"GPT 4o Mini\", \"gpt-4o-mini\"), \n",
    "                             (\"Claude Haiku 3\", \"claude-3-haiku-20240307\"), \n",
    "                             (\"Gemini 2.0 Flash\", \"gemini/gemini-2.0-flash\")], \n",
    "                    label=\"Select model\"),\n",
    "        gr.Checkbox(label=\"Stream\")\n",
    "    ],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1dd9085-ba1b-452b-9811-e76798bc90c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Week2_Day2_Litellm",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
