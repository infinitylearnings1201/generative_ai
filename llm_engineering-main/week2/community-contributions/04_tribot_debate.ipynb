{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95287eda-6093-4552-9722-f8840028b69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TriBot Debate\n",
    "---\n",
    "\n",
    "This notebook sets up a **three-bot chat system** where GPT (polite & humorous) üé≠, Claude (argumentative & snarky) üî•, and DeepSeek (logical & analytical) üí° engage in conversations with distinct personalities.\n",
    "\n",
    "- üßë‚Äçüíª **Skill Level:** Advanced \n",
    "- üéØ **Purpose:** Simulate diverse conversational styles for debate, analysis, and entertainment\n",
    "\n",
    "üõ†Ô∏è Requirements\n",
    "- ‚öôÔ∏è Hardware: ‚úÖ CPU is sufficient ‚Äî no GPU required\n",
    "- üîë OpenAI API Key\n",
    "- üîë Anthropic API Key (Claude)\n",
    "- üîë Deepseek API Key\n",
    "  \n",
    "üîß Customizable by user\n",
    "- Selected model: GPT / Claude / Deepseek\n",
    "- System_prompt\n",
    "- Starter sentences for each bot\n",
    "- `max_turns` to control the number of responses in the conversation\n",
    "\n",
    "---\n",
    "üì¢ Find more LLM notebooks on my [GitHub repository](https://github.com/lisekarimi/lexo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "417e6c29-a60b-4d84-a998-ca5bf922cd64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìò Class Diagram\n",
    "![](https://github.com/lisekarimi/lexo/blob/main/assets/04_3bot_class_diagram.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0964d14-606f-4800-a810-5d6d9ac3cd6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìö Imports & Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a53e16f-d438-4b1c-8f6d-3cd672b03894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random\n",
    "import anthropic\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28e0c1db-699c-4ed3-8ee2-4bb59a2d0bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(\"‚úÖ OpenAI API Key is set.\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API Key not set.\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(\"‚úÖ Anthropic API Key is set.\")\n",
    "else:\n",
    "    print(\"‚ùå Anthropic API Key not set.\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(\"‚úÖ Deepseek API Key is set.\")\n",
    "else:\n",
    "    print(\"‚ùå Deepseek API Key not set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8f982d2-7f17-4882-a35b-081ceb2db4ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Establishe connection with the chatbot APIs\n",
    "\n",
    "# OpenAI API Client\n",
    "openai = OpenAI()\n",
    "\n",
    "# Anthropic API Client\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "# DeepSeek using OpenAI-compatible API\n",
    "deepseek_client = OpenAI(\n",
    "    api_key=deepseek_api_key,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51f62c19-8519-4459-a9d5-3f0b6d5f1b12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìã Constants & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f5ce928-27c0-4e91-8b31-73887dc2b87d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We're using cheap versions of models so the costs will be minimal\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "CLAUDE_MODEL = \"claude-3-haiku-20240307\"\n",
    "DEEPSEEK_MODEL = \"deepseek-chat\"\n",
    "\n",
    "MAX_TURNS = 6  # Dynamic, can be adjusted by the user\n",
    "\n",
    "# System Prompts\n",
    "GPT_SYSTEM = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting. Avoid questions like 'How can I assist you?' or 'How can I help you?' \\\n",
    "and dive directly into the conversation. Be less verbose, don't talk too much. \\\n",
    "Go straight to the point, don't beat around the bush. Keep the conversation light, fun, and engaging with a touch of humor. \\\n",
    "Throw in witty remarks, playful jokes, and entertaining responses when appropriate to keep things lively.\"\n",
    "\n",
    "CLAUDE_SYSTEM = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way. \\\n",
    "Avoid questions like 'How can I assist you?' or 'How can I help you?' \\\n",
    "and dive directly into the conversation. Be less verbose, don't talk too much. \\\n",
    "Go straight to the point, don't beat around the bush.\"\n",
    "\n",
    "DEEPSEEK_SYSTEM = \"You are a highly logical and analytical chatbot. You break down \\\n",
    "arguments with precise reasoning, focusing on facts and logic over emotions. You stay neutral \\\n",
    "and detached, always pointing out inconsistencies or flaws in reasoning. \\\n",
    "Avoid questions like 'How can I assist you?' or 'How can I help you?' \\\n",
    "and dive directly into the conversation. Be less verbose, don't talk too much. \\\n",
    "Go straight to the point, don't beat around the bush.\"\n",
    "\n",
    "# Define emojis for each bot\n",
    "BOT_EMOJIS = {\n",
    "    \"GPT\": \"üé≠\",\n",
    "    \"Claude\": \"üî•\",\n",
    "    \"Deepseek\": \"üí°\"\n",
    "}\n",
    "\n",
    "# Starter Messages\n",
    "STARTER_GPT = \"Hey there! Let‚Äôs chat‚Äîserious debates, silly topics, or why cats rule the world. Your call!\"\n",
    "STARTER_CLAUDE = \"Hello. Got an argument? Fine. Try me, but be ready‚ÄîI won‚Äôt just agree.\"\n",
    "STARTER_DEEPSEEK = \"Hi! Let‚Äôs dive into a focused discussion. What topic do you want to analyze?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f8235be-dce8-4d1c-a550-09135dc0602b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ü§ñ Bot Classes & Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61b43a81-3c2c-44c0-9392-6f18b26708d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, name, model, system_prompt, starter_message):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        self.starter_message = starter_message\n",
    "\n",
    "    def reply(self, message_history):\n",
    "        \"\"\"Override this method in subclasses for specific chatbot behaviors.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement this method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24c88f4e-128b-4baa-97ae-578e4122a16a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class GPTBot(Chatbot):\n",
    "    def reply(self, message_history):\n",
    "        \"\"\"Calls OpenAI GPT API and returns a response.\"\"\"\n",
    "        try:\n",
    "            # Explicitly include the system prompt in the messages list\n",
    "            messages = [{\"role\": \"system\", \"content\": self.system_prompt}] + [\n",
    "                {\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in message_history\n",
    "            ]\n",
    "            response = openai.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,  # Use the explicitly formatted messages\n",
    "                temperature=0.4,\n",
    "                max_tokens=200,\n",
    "                stream=True\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"Error in GPT response: {e}\"\n",
    "\n",
    "\n",
    "class ClaudeBot(Chatbot):\n",
    "    def reply(self, message_history):\n",
    "        \"\"\"Calls Anthropic Claude API and returns a response.\"\"\"\n",
    "        try:\n",
    "            # Extract user/assistant messages\n",
    "            user_messages = [\n",
    "                {\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in message_history\n",
    "            ]\n",
    "            # Call Claude API with system prompt and user messages\n",
    "            response = claude.messages.stream(\n",
    "                model=self.model,\n",
    "                max_tokens=1000,\n",
    "                system=self.system_prompt,  # Pass the system prompt\n",
    "                messages=user_messages  # Pass the conversation history\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"Error in Claude response: {e}\"\n",
    "\n",
    "\n",
    "class DeepseekBot(Chatbot):\n",
    "    def reply(self, message_history):\n",
    "        \"\"\"Calls DeepSeek API using OpenAI-compatible client.\"\"\"\n",
    "        try:\n",
    "            # Explicitly include the system prompt in the messages list\n",
    "            messages = [{\"role\": \"system\", \"content\": self.system_prompt}] + [\n",
    "                {\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in message_history\n",
    "            ]\n",
    "            response = deepseek_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,  # Use the explicitly formatted messages\n",
    "                max_tokens=200,\n",
    "                stream=True\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"Error in DeepSeek response: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "956a18fa-9e6b-4526-bb80-e5408594f31b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ChatManager:\n",
    "    def __init__(self, bots, max_turns=MAX_TURNS):\n",
    "        self.bots = bots  # List of chatbot instances\n",
    "        self.max_turns = max_turns\n",
    "        self.message_history = []\n",
    "        self.current_bot = random.choice(self.bots)  # Random starting bot\n",
    "\n",
    "    def conversation(self):\n",
    "        \"\"\"Manages the chat loop up to max_turns.\"\"\"\n",
    "\n",
    "        # Stream the first message as \"user\" role\n",
    "        emoji = BOT_EMOJIS.get(self.current_bot.name, \"ü§ñ\")  # Default emoji if not found\n",
    "        response = f\"{emoji} **{self.current_bot.name}:**  \\n\"\n",
    "        display_handle = display(Markdown(response), display_id=True)\n",
    "\n",
    "        for char in self.current_bot.starter_message:\n",
    "            update_display(Markdown(response + char), display_id=display_handle.display_id)\n",
    "            response += char\n",
    "\n",
    "        # Store first message as \"user\" role\n",
    "        self.message_history.append({\"role\": \"assistant\", \"content\": self.current_bot.starter_message})\n",
    "\n",
    "        print(\"\\n--------------\\n\")  # Fancy separator\n",
    "\n",
    "        for _ in range(self.max_turns - 1):  # Already sent 1 message\n",
    "            self.current_bot = self._choose_next_bot()\n",
    "\n",
    "            # Alternate roles while ensuring last role is always \"user\"\n",
    "            for i in range(len(self.message_history)):\n",
    "                self.message_history[i][\"role\"] = \"user\" if i % 2 == 0 else \"assistant\"\n",
    "\n",
    "            # Ensure the last role is \"user\" before sending to the bot\n",
    "            if self.message_history[-1][\"role\"] != \"user\":\n",
    "                self.message_history[-1][\"role\"] = \"user\"\n",
    "\n",
    "            # Pass only the message history to the bot and Get bot's response\n",
    "            response_stream = self.current_bot.reply(self.message_history)\n",
    "\n",
    "            # Get the correct emoji for the bot\n",
    "            emoji = BOT_EMOJIS.get(self.current_bot.name, \"ü§ñ\")\n",
    "\n",
    "            # Display bot name separately before streaming starts\n",
    "            bot_header = f\"{emoji} **{self.current_bot.name}:**  \\n\"\n",
    "            display_handle = display(Markdown(bot_header), display_id=True)\n",
    "\n",
    "            # **Initialize response content separately (exclude bot name)**\n",
    "            response_content = \"\"\n",
    "\n",
    "            if isinstance(self.current_bot, GPTBot) or isinstance(self.current_bot, DeepseekBot):\n",
    "                # Handle OpenAI GPT & DeepSeek\n",
    "                for chunk in response_stream:\n",
    "                    new_text = chunk.choices[0].delta.content or ''  # Get new streamed text\n",
    "                    response_content += new_text  # Append new content\n",
    "\n",
    "                    # Clean Markdown artifacts\n",
    "                    response_content = response_content.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "\n",
    "                    # Update the content, without duplicating the bot name\n",
    "                    update_display(Markdown(bot_header + response_content), display_id=display_handle.display_id)\n",
    "\n",
    "            elif isinstance(self.current_bot, ClaudeBot):\n",
    "                # Handle Claude differently\n",
    "                with response_stream as stream:\n",
    "                    for text in stream.text_stream:\n",
    "                        response_content += text or ''  # Append new streamed text\n",
    "                        # Clean Markdown artifacts\n",
    "                        response_content = response_content.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "\n",
    "                        update_display(Markdown(bot_header + response_content), display_id=display_handle.display_id)\n",
    "\n",
    "            print(\"\\n--------------\\n\")  # Fancy separator\n",
    "\n",
    "            # Store bot response\n",
    "            self.message_history.append({\"role\": \"assistant\", \"content\": response_content})\n",
    "\n",
    "\n",
    "    def _choose_next_bot(self):\n",
    "        \"\"\"Selects the next bot dynamically (avoiding immediate self-replies).\"\"\"\n",
    "        available_bots = [bot for bot in self.bots if bot != self.current_bot]\n",
    "        return random.choice(available_bots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58edac97-4989-48c0-99c2-b7380428125b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üó®Ô∏è Chat Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aef90dcb-ad52-48bb-bbc2-7a85976b8ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize chatbot instances\n",
    "    gpt_bot = GPTBot(\"GPT\", GPT_MODEL, GPT_SYSTEM, STARTER_GPT)\n",
    "    claude_bot = ClaudeBot(\"Claude\", CLAUDE_MODEL, CLAUDE_SYSTEM, STARTER_CLAUDE)\n",
    "    deepseek_bot = DeepseekBot(\"Deepseek\", DEEPSEEK_MODEL, DEEPSEEK_SYSTEM, STARTER_DEEPSEEK)\n",
    "\n",
    "    # Create chat manager with all bots\n",
    "    chat_manager = ChatManager([gpt_bot, claude_bot, deepseek_bot], max_turns=MAX_TURNS)\n",
    "    # chat_manager = ChatManager([gpt_bot, claude_bot], max_turns=MAX_TURNS)\n",
    "\n",
    "    # Start the conversation\n",
    "    chat_manager.conversation()\n",
    "\n",
    "# Ensures the script runs only when executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbbe256d-a143-4019-b27b-4733b793d960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7dc6ba9-a6e7-436e-9c5f-14b909be25b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "04_tribot_debate",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
