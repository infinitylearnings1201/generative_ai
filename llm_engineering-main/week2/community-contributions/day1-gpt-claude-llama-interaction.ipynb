{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb60c706-589f-48e1-95dc-3139bb144ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import ollama\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9e587bf-db2e-4d62-a27b-de45f6bc9f4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82a06fb7-1687-4f24-957a-e0c457b73d37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "963a650e-b209-42da-b810-a83012045c3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "ollama_model = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50fb6f8b-86de-4960-980e-5e035412f7c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpt_system = \"You are a knowledgable but sarcastic team lead at a software development company. \\\n",
    "You manage a team with two more junior developers. \\\n",
    "You might come across as aggressive but that's just your humor. \"\n",
    "\n",
    "claude_system = \"You are one of the junior developers at a software development company. \\\n",
    "You work in a team of three. \\\n",
    "You are nerdy, introvert but gets the job done efficiently. \"\n",
    "\n",
    "llama_system = \"You are one of the junior developers at a software development company. \\\n",
    "You have two other developers in your team.\\\n",
    "You are more talks and less work kind of person. \"\n",
    "\n",
    "gpt_messages = [\"Hi, how is it going?\"]\n",
    "claude_messages = [\"Hi.\"]\n",
    "llama_messages = [\"Hey, what's up everyone?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d3d7837-eb87-4c44-b02d-6bb77a754fb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt_msg, claude_msg, llama_msg in zip(gpt_messages, claude_messages, llama_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama_msg})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5bc493b-d801-4dc6-adf3-22dd5d8b0759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19bd85e4-083a-4ae3-b710-6cbd38f3ba0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt_msg, claude_msg, llama_msg in zip(gpt_messages, claude_messages, llama_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama_msg})\n",
    "                        \n",
    "    # -- Debugging to see what messages are being passed\n",
    "    #     print(\"Messages being sent to Claude:\")\n",
    "    # for idx, msg in enumerate(messages):\n",
    "    #     print(f\"{idx}: {msg}\")\n",
    "        \n",
    "    message = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "436d94b7-0f11-49de-87c5-3d54d59ae72a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7943c1f2-5d2d-492c-ba2b-532a9ba65c41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_ollama():\n",
    "    messages = [{\"role\": \"system\", \"content\": llama_system}]\n",
    "    for gpt_msg, claude_msg, llama_msg in zip(gpt_messages, claude_messages, llama_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": llama_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=ollama_model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Llama call: {e}\")\n",
    "        return \"An error occurred in Llama.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dea36527-d9bc-49aa-accc-ad624a7f1161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "call_ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7dd9dc6-91d4-4916-a03a-e7a8cb540ed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"\\n{claude_messages[0]}\\n\")\n",
    "print(f\"\\n{llama_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "\n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    claude_messages.append(claude_next)\n",
    "\n",
    "    llama_next = call_ollama()\n",
    "    print(f\"Ollama:\\n{llama_next}\\n\")\n",
    "    llama_messages.append(llama_next)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "day1-gpt-claude-llama-interaction",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
