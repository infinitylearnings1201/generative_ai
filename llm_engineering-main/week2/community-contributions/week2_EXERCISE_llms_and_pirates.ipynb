{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab0568e1-8fd4-491f-ae92-23efe5d0a4ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LLMs and Pirates üè¥‚Äç‚ò†Ô∏èü¶ú‚öì\n",
    "The theme is of a pirate-y nature. If ye be havin' any wonderings about what a life in the seas be like, yer in the right place, matey. Arrr!\n",
    "\n",
    "This notebook demonstrates use of \n",
    "- LLM APIs: OpenAI ChatGPT, Anthropic Claude, Google Gemini\n",
    "- Gradio to build some UIs to test out the LLMs\n",
    "- Streaming mode for LLM output\n",
    "- Text-to-speech via OpenAI's TTS API\n",
    "- Image generation with DALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f592d7e-2751-4786-a239-a502e706e92b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97928974-83ee-4629-8930-66a18d750450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "\n",
    "import random\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ace51369-278f-45d6-98c3-2b2277be444b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key    = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key    = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fc9cc95-d0b3-4116-8355-78b28d333416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# initialize LLMs\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f55805d-07bb-4fcb-b694-3576cfb8db55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simple Zero-shot Example\n",
    "Example of a single question given by the user, and we check out responses from different LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f05ab93-54ee-4176-85c6-ded00dc9b956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_message = 'You are a pirate. You reply to questions in a thick pirate accent.'\n",
    "user_message = 'What is a pet name you would give to your pet turtle?'\n",
    "\n",
    "# GPT 4o mini\n",
    "print('--------------------------------------------')\n",
    "messages = [\n",
    "    {'role':'system', 'content':system_message},\n",
    "    {'role':'user',   'content':user_message}\n",
    "]\n",
    "response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "print('GPT 4o mini:')\n",
    "print(response.choices[0].message.content)\n",
    "print('--------------------------------------------')\n",
    "\n",
    "# Claude\n",
    "print('--------------------------------------------')\n",
    "response = claude.messages.create(\n",
    "    model=\"claude-3-5-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    ")\n",
    "print('Claude:')\n",
    "print(response.content[0].text)\n",
    "print('--------------------------------------------')\n",
    "\n",
    "# Gemini\n",
    "print('--------------------------------------------')\n",
    "print('Gemini:')\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash-exp',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_message)\n",
    "print(response.text)\n",
    "print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11ea62fd-459e-46c0-8626-009194b173ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Chat with a Pirate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97a0bf2e-d941-4f15-a3bd-3f1d6d3c288f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_message = 'You are a pirate. You reply to questions in a thick pirate accent.'\n",
    "\n",
    "def chat(user_message, history):\n",
    "    messages = [{'role':'system', 'content':system_message}] + history + [{'role':'user', 'content':user_message}]\n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply\n",
    "\n",
    "gr.ChatInterface(fn=chat, type='messages').launch()\n",
    "\n",
    "# Example: \n",
    "# - What is rum made of? and why are pirates so fond of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d0878ca-f571-40a4-89f2-773a821fe1bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dynamic Selection & Streaming\n",
    "Below is a sample UI with dynamic model selection. The LLM response is also returned in streaming mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1745fa73-098d-49bd-bfa4-a3c77b7109a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_message = 'You are a pirate. You reply to questions in a thick pirate accent.'\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result\n",
    "\n",
    "def stream_claude(prompt):\n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response\n",
    "\n",
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\"), gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()\n",
    "# Example\n",
    "# - What's the favorite sea for a pirate to have adventures on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30f4c0ec-845d-44aa-af7c-1643dc6199a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Voiced-out Responses\n",
    "Below is a sample UI where the LLM response is voiced out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f43e9671-8106-408d-bee5-f19539fbca1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        # model=\"tts-1\",\n",
    "        voice=\"ash\",\n",
    "        instructions=\"Speak with a thick pirate accent.\",\n",
    "        input=message)\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    output_filename = \"output_audio.mp3\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(audio_stream.read())\n",
    "\n",
    "    # Play the generated audio\n",
    "    display(Audio(output_filename, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98791768-9091-404c-ac94-0375370a61b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# small test\n",
    "talker(\"Not all treasure is gold and silver, matey.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24898140-c4c6-4daf-9044-c8269157170a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_message = 'You are a pirate. You reply to questions in a thick pirate accent.'\n",
    "\n",
    "def chat(user_message, history):\n",
    "    messages = [{'role':'system', 'content':system_message}] + history + [{'role':'user', 'content':user_message}]\n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    talker(reply)\n",
    "    return reply\n",
    "\n",
    "gr.ChatInterface(fn=chat, type='messages').launch()\n",
    "\n",
    "# Example\n",
    "# - What are some of the skills necessary for life as a pirate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb25bcb1-4491-4c8b-8f78-2ef88fa86987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## TOOLS\n",
    "Below is an example of incorporating the use of *tools* to augment our LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ee866bb-77fa-4958-96df-0f71aa0edafd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Tool 1: Pirate Quotes Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54748e42-dc53-4979-90d2-cc2197575b1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pirate_quotes = [\n",
    "    \"May your blade always be wet, and powder dry.\",\n",
    "    \"Under a black flag we sail and the sea shall be our empire.\",\n",
    "    \"Ahoy matey! Let‚Äôs trouble the water!\",\n",
    "    \"Under a black flag we shall sail.\",\n",
    "    \"Obey the captain or learn to swim.\",\n",
    "    \"I be ruler of the seven seas!\",\n",
    "    \"Shiver me timbers!\",\n",
    "    \"Avast, ye scurvy dog.\",\n",
    "    \"Walk the plank, ye scallywag.\",\n",
    "    \"Pillage and plunder.\",\n",
    "    \"Batten down the hatches.\",\n",
    "    \"Weigh anchor and hoist the mizzen.\",\n",
    "    \"Here be treasure, matey.\",\n",
    "    \"Thar she blows!\",\n",
    "    \"Yo ho ho and a bottle of rum.\",\n",
    "    \"Prepare to be boarded.\",\n",
    "    \"May your anchor be tight, your cork be loose, your rum be spiced and your compass be true.\",\n",
    "    \"Loot is first and wimmen second. Because if ye have the first ye‚Äôll have the second, but if ye have the second ye won‚Äôt have the first for long!\",\n",
    "    \"The rougher the seas, the smoother we sail. Ahoy!\",\n",
    "    \"No cause is lost if there is but one fool left to fight for it.\",\n",
    "    \"Avast ye landlubbers! Ye can throw ye lunch in Davy Jones‚Äô locker, but not yer homework!\"\n",
    "]\n",
    "\n",
    "def pirate_quoter(num_quotes):\n",
    "    print('-----------------------------------------')\n",
    "    print(f\"{num_quotes} pirate quote(s) requested\")\n",
    "    selected_pirate_quotes = random.sample(pirate_quotes, num_quotes)\n",
    "    print(selected_pirate_quotes)\n",
    "    print('-----------------------------------------')\n",
    "    return selected_pirate_quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d8e6af1-c7b7-4b0b-ab0d-112304463415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Tool 2: Pet Namer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f40ff8b-5986-4212-98dd-6ed763653cae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def pet_namer(animal):\n",
    "    print('-----------------------------------------')\n",
    "    print(f\"Name for a pet {animal} requested\")\n",
    "    messages = [\n",
    "        {'role':'system', 'content':'You are a pirate. You will be given an animal, and you will decide on some pet names that you may give it if it was your pet. You will reply with only the pet names for this animal, separated by commas.'},\n",
    "        {'role':'user',   'content':animal}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    suggested_pet_names = reply.replace('and ','').split(', ')\n",
    "    print(suggested_pet_names)\n",
    "    print('-----------------------------------------')\n",
    "    return suggested_pet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a16591ec-7ee8-4f17-ba46-e6450d2429d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Tools in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19e76e0d-4360-4d80-b44b-64c893267289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pirate_quoter_tool = {\n",
    "    \"name\": \"pirate_quoter\",\n",
    "    \"description\": \"Get random pirate quotes. Call this whenever you are asked for pirate quotes.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"num_quotes\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The number of pirate quotes requested by the user.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"num_quotes\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "pet_namer_tool = {\n",
    "    \"name\": \"pet_namer\",\n",
    "    \"description\": \"Get a pet name for a given animal. Call this whenever you are asked to suggest a name for a pet.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"animal\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The kind of animal for which to suggest a pet name.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"animal\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": pirate_quoter_tool}, \n",
    "    {\"type\": \"function\", \"function\": pet_namer_tool}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f4286b7-e178-4630-bd48-9f9ed3cdb1c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages, tools=tools)\n",
    "    \n",
    "    # handle tool calls\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        # add response to list of messages for upcoming API call (at the end of this if)\n",
    "        message = response.choices[0].message\n",
    "        messages.append(message)\n",
    "        \n",
    "        # loop over scheduled tool calls\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        for i in range(len(tool_calls)):\n",
    "            tool_call_i = tool_calls[i]\n",
    "            tool_func_i = tool_call_i.function\n",
    "            tool_name_i = tool_func_i.name\n",
    "            tool_args_i = json.loads(tool_func_i.arguments)\n",
    "            if tool_name_i == 'pirate_quoter':\n",
    "                num_quotes = tool_args_i.get('num_quotes')\n",
    "                response = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": json.dumps({\"num_quotes\": num_quotes, \"quotes\": pirate_quoter(num_quotes)}),\n",
    "                    \"tool_call_id\": tool_call_i.id\n",
    "                }\n",
    "            elif tool_name_i == 'pet_namer':\n",
    "                animal = tool_args_i.get('animal')\n",
    "                response = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": json.dumps({\"animal\": animal, \"pet_names\": pet_namer(animal)}),\n",
    "                    \"tool_call_id\": tool_call_i.id\n",
    "                }\n",
    "            messages.append(response)\n",
    "\n",
    "        # finalize tool calls\n",
    "        response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "\n",
    "    # return\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()\n",
    "\n",
    "# example tool-related requests you may ask during the conversation\n",
    "# - give me 3 pirate quotes\n",
    "# - What is a pet name you would give to your pet turtle?\n",
    "# - What are some pet names you may give to your pet monkey?\n",
    "# - give me 5 pirate quotes and then give me a couple of names you may choose for your pet seagull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc5f43d0-b1e9-4fc5-9f88-ddd5fd017c63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generating Images with DALL-E\n",
    "Now let's generate an image of a pirate with his/her favorite pet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28506259-5dd4-4e58-82dc-466e92ade559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def artist(animal):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image of a pirate with his or her favorite pet {animal}, in a classic watercolor painting style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "957e920f-ed14-45cf-be8e-f420159bd314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artist('monkey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f92c71c8-57f3-4cde-a9db-28c836d2a2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The Grande Finale\n",
    "Now, we bring everything together in one grand Gradio app!\n",
    "\n",
    "The code below is self-contained and doesn't require running of any cells above. The code below uses the OpenAI LLMs only. \n",
    "\n",
    "Now, enjoy the grand finale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2533e344-27a9-4582-a4fe-dadbb25d92de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "\n",
    "import random\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd71b157-9208-408c-9a5a-4ccc4300c927",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pirate_quotes = [\n",
    "    \"May your blade always be wet, and powder dry.\",\n",
    "    \"Under a black flag we sail and the sea shall be our empire.\",\n",
    "    \"Ahoy matey! Let‚Äôs trouble the water!\",\n",
    "    \"Under a black flag we shall sail.\",\n",
    "    \"Obey the captain or learn to swim.\",\n",
    "    \"I be ruler of the seven seas!\",\n",
    "    \"Shiver me timbers!\",\n",
    "    \"Avast, ye scurvy dog.\",\n",
    "    \"Walk the plank, ye scallywag.\",\n",
    "    \"Pillage and plunder.\",\n",
    "    \"Batten down the hatches.\",\n",
    "    \"Weigh anchor and hoist the mizzen.\",\n",
    "    \"Here be treasure, matey.\",\n",
    "    \"Thar she blows!\",\n",
    "    \"Yo ho ho and a bottle of rum.\",\n",
    "    \"Prepare to be boarded.\",\n",
    "    \"May your anchor be tight, your cork be loose, your rum be spiced and your compass be true.\",\n",
    "    \"Loot is first and wimmen second. Because if ye have the first ye‚Äôll have the second, but if ye have the second ye won‚Äôt have the first for long!\",\n",
    "    \"The rougher the seas, the smoother we sail. Ahoy!\",\n",
    "    \"No cause is lost if there is but one fool left to fight for it.\",\n",
    "    \"Avast ye landlubbers! Ye can throw ye lunch in Davy Jones‚Äô locker, but not yer homework!\"\n",
    "]\n",
    "\n",
    "def pirate_quoter(num_quotes):\n",
    "    print('-----------------------------------------')\n",
    "    print(f\"{num_quotes} pirate quote(s) requested\")\n",
    "    selected_pirate_quotes = random.sample(pirate_quotes, num_quotes)\n",
    "    print(selected_pirate_quotes)\n",
    "    print('-----------------------------------------')\n",
    "    return selected_pirate_quotes\n",
    "\n",
    "def pet_namer(animal):\n",
    "    print('-----------------------------------------')\n",
    "    print(f\"Name for a pet {animal} requested\")\n",
    "    messages = [\n",
    "        {'role':'system', 'content':'You are a pirate. You will be given an animal, and you will decide on some pet names that you may give it if it was your pet. You will reply with only the pet names for this animal, separated by commas.'},\n",
    "        {'role':'user',   'content':animal}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    suggested_pet_names = reply.replace('and ','').split(', ')\n",
    "    print(suggested_pet_names)\n",
    "    print('-----------------------------------------')\n",
    "    return suggested_pet_names\n",
    "\n",
    "pirate_quoter_tool = {\n",
    "    \"name\": \"pirate_quoter\",\n",
    "    \"description\": \"Get random pirate quotes. Call this whenever you are asked for pirate quotes.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"num_quotes\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The number of pirate quotes requested by the user.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"num_quotes\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "pet_namer_tool = {\n",
    "    \"name\": \"pet_namer\",\n",
    "    \"description\": \"Get a pet name for a given animal. Call this whenever you are asked to suggest a name for a pet.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"animal\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The kind of animal for which to suggest a pet name.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"animal\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": pirate_quoter_tool}, {\"type\": \"function\", \"function\": pet_namer_tool}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13c55991-a261-4b05-97c9-a6f7c56f66dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        # model=\"tts-1\",\n",
    "        voice=\"ash\",\n",
    "        instructions=\"Speak with a thick pirate accent.\",\n",
    "        input=message)\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    output_filename = \"output_audio.mp3\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(audio_stream.read())\n",
    "\n",
    "    # Play the generated audio\n",
    "    display(Audio(output_filename, autoplay=True))\n",
    "\n",
    "def artist(animal):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image of a pirate with his or her favorite pet {animal}, in a classic watercolor painting style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed03d12b-7737-40bd-ad41-a1e77a22844b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_message = 'You are a pirate. You reply to questions in a thick pirate accent.'\n",
    "def chat(history, pirate_pet_image):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages, tools=tools)\n",
    "    # pirate_pet_image = None\n",
    "    \n",
    "    # handle tool calls\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        # add response to list of messages for upcoming API call (at the end of this if)\n",
    "        message = response.choices[0].message\n",
    "        messages.append(message)\n",
    "        \n",
    "        # loop over scheduled tool calls\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        for i in range(len(tool_calls)):\n",
    "            tool_call_i = tool_calls[i]\n",
    "            tool_func_i = tool_call_i.function\n",
    "            tool_name_i = tool_func_i.name\n",
    "            tool_args_i = json.loads(tool_func_i.arguments)\n",
    "            if tool_name_i == 'pirate_quoter':\n",
    "                num_quotes = tool_args_i.get('num_quotes')\n",
    "                response = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": json.dumps({\"num_quotes\": num_quotes, \"quotes\": pirate_quoter(num_quotes)}),\n",
    "                    \"tool_call_id\": tool_call_i.id\n",
    "                }\n",
    "            elif tool_name_i == 'pet_namer':\n",
    "                animal = tool_args_i.get('animal')\n",
    "                response = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": json.dumps({\"animal\": animal, \"pet_names\": pet_namer(animal)}),\n",
    "                    \"tool_call_id\": tool_call_i.id\n",
    "                }\n",
    "                pirate_pet_image = artist(animal)\n",
    "            messages.append(response)\n",
    "\n",
    "        # finalize tool calls\n",
    "        response = openai.chat.completions.create(model='gpt-4o-mini', messages=messages)\n",
    "\n",
    "    # return\n",
    "    reply = response.choices[0].message.content\n",
    "    talker(reply)\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    return history, pirate_pet_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1f909db-1d10-49df-80bb-195f9f76837f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface!\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # last_image = gr.State(None)  # State to store the last valid image\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(\n",
    "        do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]\n",
    "    ).then(\n",
    "        chat, inputs=[chatbot, image_output], outputs=[chatbot, image_output]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "# Passing in inbrowser=True in the last line will cause a Gradio window to pop up immediately.\n",
    "ui.launch(inbrowser=True)\n",
    "\n",
    "# Examples:\n",
    "# - Who is Davey Jones?\n",
    "# - What are some animals that are usually taken as pets by pirates?\n",
    "# - I am thinking of getting myself a pet dog. What should I name him?\n",
    "# - Give me some pirate quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3296dab9-a079-4496-9a01-067c5d81a497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "-------\n",
    "\n",
    "# THE END\n",
    "We leave it up to the reader as exercises to incorporate the use of tools and voice/image generation with Anthropic Claude and Google Gemini. You may also extend the above UI by adding a dropdown from which the user may select a particular voice for the `talker()` function.\n",
    "\n",
    "Finally, an addition to this notebook that I would love to see is coming up with a more authentic pirate-accented voice output. Do let me know if you figure it out!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "week2_EXERCISE_llms_and_pirates",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
