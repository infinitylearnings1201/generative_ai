{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa6edd70-a871-424a-b113-4d753641bcc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90a5c0b9-ae36-4f8a-a146-d096f71b5797",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ff2f7cc-990d-434d-9902-3d66648a32bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Multimodal question and answerer:\n",
    " - The chatbot answers technical questions\n",
    " - The user can enter their language of choice (that exists) and it would be translated real time on the second screen and English on the first screen.\n",
    " - The user can also choose which tone/mood it would like the responses to have.\n",
    " - The user can choose whether the ersponse will be read out loud or not. \n",
    " - The user can send in an audio and get the response back in audio (automatically) if he so chooses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0c04b25-062c-449d-9a74-739edf40a86e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce38647e-34fe-4b6d-bc58-595db1009580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(\"OpenAI key exists!\")\n",
    "else:\n",
    "    print(\"OpenAI key not set!\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(\"Anthropic API key exists!\")\n",
    "else:\n",
    "    print(\"Anthropic key not set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f00ad9-a08d-4808-9fb4-b55f4e60c51c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "openai_4o_mini_model = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65e8e55e-c805-428d-829a-c88077c34185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that answers tchnical questions.\"\n",
    "system_message += \"Always be accurate. If you don't know or not sure about some information, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d291731-d012-4495-b8e7-1623594a0711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf50cf09-ec2d-4df4-a9c9-f7e0587119b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# First install deep_translator:\n",
    "# pip install deep_translator\n",
    "\n",
    "# Top 10 most spoken languages with their codes\n",
    "LANGUAGES = {\n",
    "    \"English\": \"en\",\n",
    "    \"Mandarin Chinese\": \"zh-CN\",\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Spanish\": \"es\",\n",
    "    \"Arabic\": \"ar\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Portuguese\": \"pt\",\n",
    "    \"Russian\": \"ru\",\n",
    "    \"Japanese\": \"ja\",\n",
    "    \"German\": \"de\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6562a956-5604-440f-af46-963c0209feb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ChatState:\n",
    "    def __init__(self):\n",
    "        self.speak = True\n",
    "        self.target_lang = \"en\"\n",
    "\n",
    "chat_state = ChatState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f43ff2af-5782-42ff-a821-c6d0e147d36c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def translate_message(text, target_lang):\n",
    "    if target_lang == \"en\":\n",
    "        return text\n",
    "    try:\n",
    "        translator = GoogleTranslator(source='auto', target=target_lang)\n",
    "        return translator.translate(text)\n",
    "    except:\n",
    "        return f\"Translation error: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b8aacf9-ea2d-4f55-88e2-a404fbc7c73d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    # Original chat processing\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}] \n",
    "    response = openai.chat.completions.create(model = openai_4o_mini_model, messages = messages)\n",
    "    response_text = response.choices[0].message.content\n",
    "    \n",
    "    if chat_state.speak:\n",
    "        talker(response_text)\n",
    "    \n",
    "    # Translate messages\n",
    "    translated_message = translate_message(message, chat_state.target_lang)\n",
    "    translated_response = translate_message(response_text, chat_state.target_lang)\n",
    "    \n",
    "    gr.Chatbot.update(value=[(translated_message, translated_response)], visible=True)\n",
    "    \n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbc0e136-c8b6-49c2-a104-e0700ba63edc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90fdf055-a86c-4db2-9285-8f912ae81690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "def text_to_speech(text, lang_code):\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang=lang_code)\n",
    "        # Create temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:\n",
    "            tts.save(fp.name)\n",
    "            return fp.name\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bfac262-bc2d-4aaf-a4d7-eed70ac4c60d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def respond(message, history):\n",
    "        bot_response, history_original, history_translated = process_message(\n",
    "            message, \n",
    "            history, \n",
    "            'translated' if speech_language.value.lower() == 'translated' else 'original'\n",
    "        )\n",
    "        return \"\", history_original, history_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa0cfccf-c86b-4d40-9723-f4792d36e8ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_message(message, history, speech_mode):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}] \n",
    "    response = openai.chat.completions.create(model = openai_4o_mini_model, messages = messages)\n",
    "    response_text = response.choices[0].message.content\n",
    "    \n",
    "    # Create audio if speech is enabled\n",
    "    audio_path = None\n",
    "    if chat_state.speak:\n",
    "        if speech_mode == \"Translated\":\n",
    "            translated_text = translate_message(response_text, chat_state.target_lang)\n",
    "            audio_path = text_to_speech(translated_text, chat_state.target_lang)\n",
    "        else:\n",
    "            talker(response_text)\n",
    "    \n",
    "    # Translate messages for display\n",
    "    translated_message = translate_message(message, chat_state.target_lang)\n",
    "    translated_response = translate_message(response_text, chat_state.target_lang)\n",
    "    \n",
    "    history_original = history + [\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "        {\"role\": \"assistant\", \"content\": response_text}\n",
    "    ]\n",
    "    history_translated = [\n",
    "        {\"role\": \"user\", \"content\": translated_message},\n",
    "        {\"role\": \"assistant\", \"content\": translated_response}\n",
    "    ]\n",
    "    \n",
    "    return response_text, history_original, history_translated, audio_path\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    speech_mode = gr.State(\"Original\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        speak_checkbox = gr.Checkbox(\n",
    "            label=\"Read responses aloud\",\n",
    "            value=True,\n",
    "            interactive=True\n",
    "        )\n",
    "        language_dropdown = gr.Dropdown(\n",
    "            choices=list(LANGUAGES.keys()),\n",
    "            value=\"Spanish\",\n",
    "            label=\"Translation Language\",\n",
    "            interactive=True\n",
    "        )\n",
    "        speech_language = gr.Radio(\n",
    "            choices=[\"Original\", \"Translated\"],\n",
    "            value=\"Original\",\n",
    "            label=\"Speech Language\",\n",
    "            interactive=True\n",
    "        )\n",
    "    \n",
    "    # Add audio player\n",
    "    audio_player = gr.Audio(label=\"Response Audio\", visible=True)\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### Original Conversation\")\n",
    "            chatbot_original = gr.Chatbot(type=\"messages\")\n",
    "            msg_original = gr.Textbox(label=\"Message\")\n",
    "            send_btn = gr.Button(\"Send\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### Translated Conversation\")\n",
    "            chatbot_translated = gr.Chatbot(type=\"messages\")\n",
    "    \n",
    "    state = gr.State([])\n",
    "    \n",
    "    def respond(message, history, current_speech_mode):\n",
    "        bot_response, history_original, history_translated, audio_path = process_message(\n",
    "            message, \n",
    "            history,\n",
    "            current_speech_mode\n",
    "        )\n",
    "        \n",
    "        return \"\", history_original, history_translated, audio_path\n",
    "    \n",
    "    send_btn.click(\n",
    "        respond,\n",
    "        inputs=[msg_original, state, speech_language],\n",
    "        outputs=[msg_original, chatbot_original, chatbot_translated, audio_player],\n",
    "    )\n",
    "    \n",
    "    msg_original.submit(\n",
    "        respond,\n",
    "        inputs=[msg_original, state, speech_language],\n",
    "        outputs=[msg_original, chatbot_original, chatbot_translated, audio_player],\n",
    "    )\n",
    "    \n",
    "    speak_checkbox.change(fn=lambda x: setattr(chat_state, 'speak', x), inputs=[speak_checkbox])\n",
    "    language_dropdown.change(fn=update_language, inputs=[language_dropdown])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db60dc37-a563-43cc-b08d-e3213ec445c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bf00d3f-9d8e-426e-9ec5-80bacf524d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ceffe10d-4808-405b-89cf-6cb79d6d3e85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!ffmpeg -version\n",
    "!ffprobe -version\n",
    "!ffplay -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a61e8766-49ae-432f-b041-24932852a4a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd2c10c3-640b-4d9d-b68d-b50eb28d40a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model = \"tts-1\",\n",
    "        voice = \"onyx\",\n",
    "        input = message\n",
    "    )\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    output_filename = \"output_audio.mp3\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(audio_stream.read())\n",
    "\n",
    "    #Play the generated audio\n",
    "    display(Audio(output_filename, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0b2dd89-19f6-4976-a3a3-773ec5ac55b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "talker(\"Warm, wet, and wild?! There must be something in the water!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61b6b2b3-8ccd-4bc9-b45e-d60723967a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "week2_exercise_translated_chatbot",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
